{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using vectorized mini-batch SGD\n",
    "\n",
    "This notebook is part of article [Explaining RNNs without neural networks](https://explained.ai/rnn/index.html) and notebook [prep.ipynb](prep.ipynb) should be run this notebook as it needs files: `data/X.pkl` and `data/y.pkl`.\n",
    "\n",
    "Instead of processing batch one record at a time from time 1 to time len(word), process all time steps t across all batch records at once, then proceed to time step (char index) t+1.  This allows us to vectorize and perform each time step in parallel.  We effectively remove a loop.\n",
    "\n",
    "But, it means we must pad to have same length in batch. We pad on left so the zero vectors are ignored to get same answer as record-by-record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "from support import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "with open('data/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TESTING SUBSAMPLE\n",
    "idx = list(np.random.randint(0,len(X),size=2000))\n",
    "X = np.array(X)[idx].tolist()\n",
    "y = np.array(y)[idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_matrix(X, max_len, vocab, verbose=False):\n",
    "    X_onehot = torch.zeros(len(X),max_len,len(vocab), dtype=torch.float64)\n",
    "    for i,x in enumerate(X):\n",
    "        pad = max_len - len(x)\n",
    "        for j,c in enumerate(x):\n",
    "            X_onehot[i, j+pad, ctoi[c]] = 1\n",
    "        if verbose: print(x); print(X_onehot[i].T, \"\\n\")\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X:Sequence[Sequence], max_len:int, vocab:dict):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "    X_onehot = onehot_matrix(X, max_len, vocab)\n",
    "    h = torch.zeros(nhidden, len(X), dtype=torch.float64, requires_grad=False)\n",
    "    for j in range(max_len):\n",
    "        x_step_t = X_onehot[:,j].T\n",
    "        h = W.mm(h) + U.mm(x_step_t)\n",
    "        h = torch.tanh(h)        \n",
    "    o = V.mm(h)\n",
    "    o = o.T # make it batch_size x nclasses\n",
    "    o = softmax(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just some matrices. First, set up hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ctoi = getvocab(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with trivial data set\n",
    "\n",
    "Set TESTING=True to test vs full X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING = False\n",
    "\n",
    "nhidden = 100\n",
    "batch_size = 32\n",
    "\n",
    "if TESTING:\n",
    "    nhidden = 2\n",
    "    batch_size = 2\n",
    "\n",
    "    X_train = [['a','b'],['c','d','e'], # batch 1\n",
    "               ['f'],['c','a'], # batch 2\n",
    "               ['e']] # strip\n",
    "    y_train = [0,2,1,1,2]\n",
    "\n",
    "    X_valid = X_train\n",
    "    y_valid = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,688 training records, batch size 32, 29 features (chars), 18 target languages, state is 100-vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "n = len(X_train)\n",
    "\n",
    "nbatches = n // batch_size\n",
    "n = nbatches * batch_size\n",
    "X_train = X_train[0:n]\n",
    "y_train = y_train[0:n]\n",
    "vocab, ctoi = getvocab(X_train)\n",
    "max_len = get_max_len(X_train)\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(torch.unique(torch.tensor(y_train)))\n",
    "\n",
    "print(f\"{n:,d} training records, batch size {batch_size}, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['b', 'a', 'k', 'h', 's', 'h', 'i', 'e', 'v'], ['b', 'a', 'z', 'z', 'i']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_onehot = onehot_matrix(X_train, max_len, vocab, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With verbose and trivial X_train we get:\n",
    "\n",
    "```\n",
    "tensor([[[0., 0., 0., 0., 0., 0.],\n",
    "         [1., 0., 0., 0., 0., 0.],\n",
    "         [0., 1., 0., 0., 0., 0.]],\n",
    "\n",
    "        [[0., 0., 1., 0., 0., 0.],\n",
    "         [0., 0., 0., 1., 0., 0.],\n",
    "         [0., 0., 0., 0., 1., 0.]],\n",
    "\n",
    "        [[0., 0., 0., 0., 0., 0.],\n",
    "         [0., 0., 0., 0., 0., 0.],\n",
    "         [0., 0., 0., 0., 0., 1.]],\n",
    "\n",
    "        [[0., 0., 0., 0., 0., 0.],\n",
    "         [0., 0., 1., 0., 0., 0.],\n",
    "         [1., 0., 0., 0., 0., 0.]]], dtype=torch.float64)\n",
    "```\n",
    "\n",
    "With `X_onehot.shape` = [4, 3, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using vectorized minibatch SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  2.1040 accur 0.590 | train loss  1.2162 accur 0.674 | valid loss  1.3486 accur 0.661\n",
      "Epoch:   2 accum loss  1.1664 accur 0.685 | train loss  0.9748 accur 0.730 | valid loss  1.1299 accur 0.697\n",
      "Epoch:   3 accum loss  1.0233 accur 0.713 | train loss  0.8511 accur 0.752 | valid loss  1.0187 accur 0.723\n",
      "Epoch:   4 accum loss  0.9163 accur 0.738 | train loss  0.7774 accur 0.768 | valid loss  0.9914 accur 0.729\n",
      "Epoch:   5 accum loss  0.8543 accur 0.750 | train loss  0.8635 accur 0.744 | valid loss  1.1014 accur 0.716\n",
      "Epoch:   6 accum loss  0.8327 accur 0.754 | train loss  0.7885 accur 0.777 | valid loss  1.0281 accur 0.742\n",
      "Epoch:   7 accum loss  0.7967 accur 0.761 | train loss  0.7536 accur 0.775 | valid loss  1.0030 accur 0.735\n",
      "Epoch:   8 accum loss  0.7694 accur 0.771 | train loss  0.7198 accur 0.786 | valid loss  0.9917 accur 0.744\n",
      "Epoch:   9 accum loss  0.7449 accur 0.778 | train loss  0.7049 accur 0.788 | valid loss  0.9758 accur 0.751\n",
      "Epoch:  10 accum loss  0.7356 accur 0.780 | train loss  0.7641 accur 0.779 | valid loss  1.0698 accur 0.741\n",
      "Epoch:  11 accum loss  0.7155 accur 0.784 | train loss  0.6708 accur 0.798 | valid loss  0.9945 accur 0.757\n",
      "Epoch:  12 accum loss  0.7221 accur 0.783 | train loss  0.6806 accur 0.797 | valid loss  1.0233 accur 0.752\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.6 s, sys: 885 ms, total: 40.5 s\n",
      "Wall time: 40.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden,    nhidden,   dtype=torch.float64, requires_grad=True)\n",
    "U = torch.randn(nhidden,  nfeatures, dtype=torch.float64, requires_grad=True) # embed one-hot char vec\n",
    "V = torch.randn(nclasses, nhidden,   dtype=torch.float64, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.005, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total = 0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        batch_X = X_train[p:p+batch_size]\n",
    "        batch_y = y_train[p:p+batch_size]\n",
    "        batch_X_onehot = onehot_matrix(batch_X, max_len, vocab)\n",
    "        H = torch.zeros(nhidden, batch_size, dtype=torch.float64, requires_grad=False)\n",
    "        for t in range(max_len):\n",
    "            x_step_t = batch_X_onehot[:,t].T # make it len(vocab) x batch_size\n",
    "            H = W.mm(H) + U.mm(x_step_t)\n",
    "            H = torch.tanh(H)\n",
    "        o = V.mm(H)\n",
    "        o = o.T # make it batch_size x nclasses\n",
    "        o = softmax(o)\n",
    "        loss = cross_entropy(o, batch_y)\n",
    "#         print(loss.item())\n",
    "        correct = torch.argmax(o, dim=1)==batch_y\n",
    "        epoch_training_accur += torch.sum(correct)\n",
    "        total += len(batch_y)\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    epoch_training_loss /= nbatches\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train, max_len, vocab)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train).item()\n",
    "        correct = torch.argmax(o, dim=1).detach()==torch.tensor(y_train)\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid, max_len, vocab)\n",
    "        valid_loss = cross_entropy(o, y_valid).item()\n",
    "        correct = torch.argmax(o, dim=1).detach()==torch.tensor(y_valid)\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing on 80% training from full data set:\n",
    "\n",
    "```\n",
    "CPU times: user 40.3 s, sys: 749 ms, total: 41 s\n",
    "Wall time: 41 s\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
