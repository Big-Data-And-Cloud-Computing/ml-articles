{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using pure SGD, one record used to compute gradient\n",
    "\n",
    "This notebook is part of article [Explaining RNNs without neural networks](https://explained.ai/rnn/index.html) and notebook [prep.ipynb](prep.ipynb) should be run this before notebook as it needs files: `data/X.pkl` and `data/y.pkl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "!if ! test -f support.py; then wget https://raw.githubusercontent.com/parrt/ml-articles/master/rnn/notebooks/support.py; fi\n",
    "    \n",
    "from support import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "with open('data/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TESTING SUBSAMPLE\n",
    "idx = list(np.random.randint(0,len(X),size=2000))\n",
    "X = np.array(X)[idx].tolist()\n",
    "y = np.array(y)[idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward1(x):\n",
    "    h = torch.zeros(nhidden, 1, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "    for j in range(len(x)):  # for each char in a name\n",
    "        x_onehot = onehot(x[j])\n",
    "        h = W.mm(h) + U.mm(x_onehot)# + b\n",
    "        h = torch.tanh(h)\n",
    "    # h is output of RNN, a fancy CBOW embedding for variable-length sequence in x\n",
    "    # run through a final layer to map that h to a one-hot encoded predicted class\n",
    "    o = V.mm(h)# + Vb\n",
    "    o = o.reshape(1,nclasses)\n",
    "    o = softmax(o)\n",
    "    return o\n",
    "\n",
    "def forward(X:Sequence[Sequence]):#, apply_softmax=True):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "    outputs = []\n",
    "    for i in range(0, len(X)): # for each input record\n",
    "        o = forward1(X[i])\n",
    "        outputs.append( o[0] ) \n",
    "    return torch.stack(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just some matrices. First, set up hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ctoi = getvocab(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(c) -> torch.tensor:\n",
    "    v = torch.zeros((len(vocab),1), dtype=torch.float64)\n",
    "    v[ctoi[c]] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,699 training records, 29 features (chars), 18 target languages, state is 100-vector\n"
     ]
    }
   ],
   "source": [
    "nhidden = 100\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(torch.unique(y_train))\n",
    "n = len(X_train)\n",
    "print(f\"{n:,d} training records, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using pure SGD, one record used to compute gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  1.8632 accur 0.572 | train loss  1.3631 accur 0.630 | valid loss  1.4232 accur 0.621\n",
      "Epoch:   2 accum loss  1.2518 accur 0.642 | train loss  1.0512 accur 0.686 | valid loss  1.1463 accur 0.664\n",
      "Epoch:   3 accum loss  1.1332 accur 0.675 | train loss  0.9880 accur 0.713 | valid loss  1.0933 accur 0.690\n",
      "Epoch:   4 accum loss  1.0389 accur 0.697 | train loss  0.9729 accur 0.707 | valid loss  1.1507 accur 0.672\n",
      "Epoch:   5 accum loss  0.9929 accur 0.707 | train loss  0.9387 accur 0.713 | valid loss  1.1153 accur 0.685\n",
      "Epoch:   6 accum loss  0.9521 accur 0.720 | train loss  0.9377 accur 0.719 | valid loss  1.1068 accur 0.682\n",
      "Epoch:   7 accum loss  0.9427 accur 0.728 | train loss  0.8602 accur 0.733 | valid loss  1.0550 accur 0.694\n",
      "Epoch:   8 accum loss  0.9125 accur 0.731 | train loss  0.8707 accur 0.736 | valid loss  1.0695 accur 0.689\n",
      "Epoch:   9 accum loss  0.8819 accur 0.736 | train loss  0.8591 accur 0.740 | valid loss  1.0719 accur 0.710\n",
      "Epoch:  10 accum loss  0.8569 accur 0.741 | train loss  0.9523 accur 0.717 | valid loss  1.1408 accur 0.681\n",
      "Epoch:  11 accum loss  0.8464 accur 0.744 | train loss  0.8860 accur 0.726 | valid loss  1.0952 accur 0.686\n",
      "Epoch:  12 accum loss  0.8456 accur 0.751 | train loss  0.7898 accur 0.769 | valid loss  1.0198 accur 0.736\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 51s, sys: 2.91 s, total: 4min 54s\n",
      "Wall time: 4min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden,    nhidden,   dtype=torch.float64, requires_grad=True)\n",
    "U = torch.randn(nhidden,  nfeatures, dtype=torch.float64, requires_grad=True) # embed one-hot char vec\n",
    "V = torch.randn(nclasses, nhidden,   dtype=torch.float64, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.001, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    for i in range(0, n): # an epoch trains all input records\n",
    "        x = X_train[i]\n",
    "        h = torch.zeros(nhidden, 1, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for j in range(len(x)):  # for each char in a name\n",
    "            h = W.mm(h) + U.mm(onehot(x[j]))\n",
    "            h = torch.tanh(h)\n",
    "        # h is output of RNN, a fancy CBOW embedding for variable-length sequence in x\n",
    "        # run through a final layer to map that h to a one-hot encoded predicted class\n",
    "#         h = dropout(h, p=0.3)\n",
    "        o = V.mm(h)\n",
    "        o = o.reshape(1,nclasses)\n",
    "        o = softmax(o)\n",
    "\n",
    "        loss = cross_entropy(o, y_train[i])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "#         print(loss.item())\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "        correct = torch.argmax(o[0])==y_train[i]\n",
    "        epoch_training_accur += correct\n",
    "\n",
    "    epoch_training_loss /= n\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train)\n",
    "        correct = torch.argmax(o, dim=1).detach()==y_train\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid)\n",
    "        valid_loss = cross_entropy(o, y_valid)\n",
    "        correct = torch.argmax(o, dim=1).detach()==y_valid\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing on 80% training from full data set:\n",
    "\n",
    "```\n",
    "CPU times: user 4min 51s, sys: 2.91 s, total: 4min 54s\n",
    "Wall time: 4min 53s\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
