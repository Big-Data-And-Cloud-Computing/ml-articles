<chapter title="Clarifying exceptions and visualizing tensor operations in deep learning code" author={[Terence Parr](http://parrt.cs.usfca.edu) and [Oliver Zeigermann](https://zeigermann.eu)}>
		 
	One of the biggest challenges when writing code to implement deep learning networks, particularly for beginners, is getting all of the tensor (matrix and vector) dimensions to line up properly. It's really easy to lose track of tensor dimensionality in complicated expressions involving multiple tensors and tensor operations. In fact, it's perhaps best to start exploring deep learning using a high-level library, such as Keras or fastai, to avoid a lot of the details. Ultimately, however, we think it's important to understand the underlying tensor arithmetic by implementing your own network layers and so on. When you do, you're going to run into some less than helpful exception messages.

In this article, we demonstrate the functionality of a new library called [TensorSensor](https://github.com/parrt/tensor-sensor) (`pip install tensor-sensor`) that aims to help programmers debug tensor code.  what does it do: clarify to augment messages and visualize Python code indicating dimensions of tensor operand.

We assume familiarity with the fundamentals of neural networks, matrix algebra, etc...

to understand the implementation part you need experience with language implementation.

I think the audience is really people doing tensor math code which is not people doing keras and such.  maybe I need to say that up front

<section title="Isolating issues in tensor code is maddening!">

Even for experts, it can be hard to quickly identify the cause of an exception in a line of Python code performing tensor operations.  The debugging process usually involves adding a print statement in front of the offending line to emit the shape of each tensor operand.  That works but requires editing the code to create the debugging statement and rerunning the training process. Or, we can manually click or type commands to request all operand shapes using an interactive debugger. (This can be less practical in an IDE like PyCharm where executing code in debug mode is much slower.)

<subsection title="Debugging a simple linear layer">
	
Let's look at a simple tensor computation to illustrate the less-than-optimal information provided by the default exception message. Consider the following simple NumPy implementation for a hardcoded single (linear) network layer that contains a tensor dimension error.

```
import numpy as np

n = 200                          # number of instances
d = 764                          # number of instance features
n_neurons = 100                  # how many neurons in this layer?

W = np.random.rand(d,n_neurons)  # Ooops! Should be (n_neurons,d) <=======
b = np.random.rand(n_neurons,1)
X = np.random.rand(n,d)          # fake input matrix with n rows of d-dimensions

Y = W @ X.T + b                  # pass all X instances through layer
```

Executing that code triggers an exception whose important elements are:

<html>
<div class=exception>...
---> 10 Y = W @ X.T + b
	
ValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 764 is different from 100)</div>
</html>

The exception identifies the offending line and which operation (`matmul`: matrix multiply) but would be more useful if it gave the complete tensor dimensions. Also, the exception would be unable to distinguish between multiple matrix multiplications occurring in one line of Python.

Next, let's see how TensorSensor makes debugging that statement much easier. If we wrap the statement using a Python `with` statement and `tsensor`'s `clarify()`, we get a visualization and an augmented error message. 

```
import tsensor
with tsensor.clarify():
    Y = W @ X.T + b
```

<html>
<img src="images/numpy-mm-py.svg" width="20%">
<div class=exception>...
ValueError: matmul: Input operand ...
Cause: @ on tensor operand W w/shape (764, 100) and operand X.T w/shape (764, 200)</div>
</html>

It's clear from the visualization that `W`'s dimensions should be flipped to be `n_neurons x d`; the columns of `W` must match the rows of `X.T`. You can also checkout a [complete side-by-side image](images/numpy-mm.png) with and without `clarify()` to see what it looks like in a notebook.

The `clarify()` functionality incurs no overhead on the executing program until an exception occurs. Upon exception, `clarify()`:

<ol>
	<li> Augments the exception object's message created by the underlying tensor library.
	<li> Gives a visual representation of the tensor sizes involved in the offending operation; only the operands and operator involved in the exception are highlighted, while the other Python elements are de-highlighted.
</ol>

TensorSensor also clarifies tensor-related exceptions raised by PyTorch and TensorFlow. Here are the equivalent code snippets and resulting augmented exception error messages (`Cause: @ on tensor ...`) and visualization from TensorSensor:
	
<table>
	<tr>
			<th width="50%">PyTorch
				<th>TensorFlow
	<tr>
<td align="left">
```
import torch
W = torch.rand(d,n_neurons)
b = torch.rand(n_neurons,1)
X = torch.rand(n,d)
with tsensor.clarify():
    Y = W @ X.T + b
```
<td align="left">
```
import tensorflow as tf
W = tf.random.uniform((d,n_neurons))
b = tf.random.uniform((n_neurons,1))
X = tf.random.uniform((n,d))
with tsensor.clarify():
    Y = W @ tf.transpose(X) + b
```
<tr>
<td>
<html>
<img src="images/mm.svg" width="40%">
<div class=exception>RuntimeError: size mismatch, m1: [764 x 100], m2: [764 x 200] at /tmp/pip-req-build-as628lz5/aten/src/TH/generic/THTensorMath.cpp:41
Cause: @ on tensor operand W w/shape [764, 100] and operand X.T w/shape [764, 200]</div>

<td>
<html>
<img src="images/tf-mm.svg" width="70%">
<div class=exception>InvalidArgumentError: Matrix size-incompatible: In[0]: [764,100], In[1]: [764,200] [Op:MatMul]
Cause: @ on tensor operand W w/shape (764, 100) and operand tf.transpose(X) w/shape (764, 200)</div>
</html>
</table>

The PyTorch message does not identify which operation triggered the exception, but TensorFlow's message does indicate matrix multiplication. Both show the operand dimensions. These default exception messages are probably good enough for this simple tensor expression for a linear layer.

You might be wondering, though, why tensor libraries don't generate a more helpful exception message that identified the names of the Python variables involved in the offending subexpression.  It's not that the library authors simply didn't bother. The fundamental issue is that Python tensor libraries are wrappers around extremely efficient cores written in C or C++. Python passes, say, the data for two tensors to a C++ function, but not the associated tensor variable names in Python space. An exception caught deep in C++ has no access to the local and global variable spaces in Python, so it just throws a generic exception back over the fence.  Because Python traps exceptions at the statement level, it also cannot isolate the subexpression within the statement.  (To learn how TensorSensor manages to generate such specific messages, check out the section below.)

<subsection title="Debugging a complex tensor expression">
	
That lack of specificity makes it hard to identify bad subexpressions within more complicated statements that contain lots of operators. For example, here's a statement pulled from the guts of a Gated Recurrent Unit (GRU) implementation:

```
h_ = torch.tanh(Whh_ @ (r*h) + Uxh_ @ X.T + bh_)
```

It doesn't matter what it's computing or what the variables represent, just that they are tensor variables. There are two matrix multiplications, two vector additions, and even a vector element-wise modification (`r*h`).  Without augmented error messages or visualizations we wouldn't know which operator and operands caused an exception. To demonstrate how TensorSensor clarifies exceptions in this case, we need to give some fake definitions for the variables used in the statement (the assignment to `h_`) to get executable code:

```
nhidden = 256
Whh_ = torch.eye(nhidden, nhidden)  # Identity matrix
Uxh_ = torch.randn(d, nhidden)
bh_  = torch.zeros(nhidden, 1)
h = torch.randn(nhidden, 1)         # fake previous hidden state h
r = torch.randn(nhidden, 1)         # fake this computation
X = torch.rand(n,d)                 # fake input

with tsensor.clarify():
    h_ = torch.tanh(Whh_ @ (r*h) + Uxh_ @ X.T + bh_)
```

Again, you can ignore the actual computation performed by the code to focus on the shape of the tensor variables.  

For most of us, it's impossible to identify the problem just by looking at the tensor dimensions and the tensor code.  The default exception message is helpful of course, but most of us will still struggle to identify the problem.  Here are the key bits of the default exception message (note the less-than-helpful reference to the C++ code):

<html>
<div class=exception>---> 10     h_ = torch.tanh(Whh_ @ (r*h) + Uxh_ @ X.T + bh_)
RuntimeError: size mismatch, m1: [764 x 256], m2: [764 x 200] at /tmp/pip-req-build-as628lz5/aten/src/TH/generic/THTensorMath.cpp:41
</div>
</html>

What we need to know is which operator and operands failed, then we can look at the dimensions to identify the problem.  Here is TensorSensor's visualization and augmented exception message:

<html>
	<img src="images/torch-gru.svg" width="55%">
<div class=exception>---> 10 h_ = torch.tanh(Whh_ @ (r*h) + Uxh_ @ X.T + bh_)
RuntimeError: size mismatch, m1: [764 x 256], m2: [764 x 200] at /tmp/pip-req-build-as628lz5/aten/src/TH/generic/THTensorMath.cpp:41
Cause: @ on tensor operand Uxh_ w/shape [764, 256] and operand X.T w/shape [764, 200]
</div>
</html>

The human eye quickly latches onto the indicated operator and the dimensions on the matrix-matrix multiply. Ooops: The columns of `Uxh_` must match the rows of `X.T`. `Uxh_` has its dimensions flipped and should be:

```
Uxh_ = torch.randn(nhidden, d)
```

At this point, we've only used our own tensor computations specified directly within the `with` code block. What about exceptions triggered within a tensor library's prebuilt network layer?

<subsection title="Clarifying exceptions triggered within prebuilt layers">

TensorSensor visualizes the last piece of code before it enters your chosen tensor library. For example, let's use the standard PyTorch `nn.Linear` linear layer but pass in an `X` matrix that is `n x n`, instead of the proper `n x d`:

```
L = torch.nn.Linear(d, n_neurons)
X = torch.rand(n,n) # oops! Should be n x d
with tsensor.clarify():
    Y = L(X)
```

<table>
	<tr>
			<th width="30%">Visualization
				<th>Augmented exception message
	<tr><td><img src="images/torch-nn-linear.svg" width="47%">
		<td><html>
<div class=exception>RuntimeError: size mismatch, m1: [200 x 200], m2: [764 x 100] at /tmp/pip-req-build-as628lz5/aten/src/TH/generic/THTensorMath.cpp:41
Cause: L(X) tensor arg X w/shape [200, 200]</div>
</html>
</table>

TensorSensor treats calls into tensor libraries as operators, whether the call is to a network layer or something simple like `torch.dot(a,b)`. Exceptions triggered within library functions yield messages that identify the function and dimensionality of any tensor arguments.

<section title="Clarifying deeply-buried tensor code">

When using a high-level library like Keras with pre-built layer objects, we get excellent error messages that indicate a mismatch in dimensionality between the layers of deep learning network. If you're building a custom layer, however, or just implementing your own to understand deep learning more thoroughly, you'll need to examine exceptions triggered inside your layer objects. TensorSensor descends into any code initiated from within the `with` statement block, stopping only when it reaches a tensor library function.

As a demonstration, let's create our own linear network layer by wrapping the simple linear layer code from above in a class definition:
	
```
class Linear:
    def __init__(self, d, n_neurons):
        self.W = torch.randn(n_neurons, d)
        self.b = torch.zeros(n_neurons, 1)
    def __call__(self, input):
        return self.W @ input + self.b
```

Then, we can create a layer as an object and perform a forward computation using some fake input `X`:

```
L = Linear(d, n_neurons) # create a layer
X = torch.rand(n, d)     # fake input
with tsensor.clarify():
    Y = L(X)             # L(X) invokes L.__call__()
```

The `Linear` layer has the correct dimensionality on weights `W` and bias `b`, but the equation in `__call__()` incorrectly references `input` rather than the transpose of that input matrix, triggering an exception:
 	
<html>
<img src="images/torch-linear.svg" width="35%">
<div class=exception>---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-20-b6b1bd407c61> in &lt;module>
      9 
     10 with tsensor.clarify(hush_errors=False):
---> 11     Y = L(X)

&lt;ipython-input-16-678a8372f1c2> in __call__(self, x)
      4         self.b = torch.zeros(n_neurons, 1)
      5     def __call__(self, x):
----> 6         return self.W@x + self.b    # L(X) invokes L.__call__()

RuntimeError: size mismatch, m1: [100 x 764], m2: [200 x 764] at /tmp/pip-req-build-as628lz5/aten/src/TH/generic/THTensorMath.cpp:41
Cause: @ on tensor operand self.W w/shape [100, 764] and operand x w/shape [200, 764]</div>
</html>

Because `L(X)` invokes our own code, not a tensor library function, TensorSensor clarifies the offending statement in `__call__()` rather than the `Y=L(X)` statement within the `with` block.

So far we've focused on clarifying exceptions, but sometimes we simply want to explain some correct tensor code to others or to make it easier to read. It's also the case that not all erroneous code triggers an exception; sometimes, we simply get the wrong answer. If that wrong answer has the wrong shape, TensorSensor can help.  Next, we introduce TensorSensor's `explain()` functionality.

<section title="Visualizing tensor code without triggering exceptions">

Debugging tensor code that uses matrices beyond two dimensions can be even more challenging. For example, it's very common to train deep learning networks in batches for performance reasons.  That means reshaping the input matrix, `X`, into `n_batches x batch_size x d` rather than `n x d`. The following code simulates passing multiple batches through a linear layer but incorrectly passes the entire 3D `X` instead of 2D batches.

```
n = 200                          # number of instances
d = 764                          # number of instance features
n_neurons = 100                  # how many neurons in this layer?
batch_size = 10                  # how many records per batch?
n_batches = n // batch_size

L = Linear(d,n_neurons) # Assume this is correct
X = torch.rand(n_batches,batch_size,d)

with tsensor.clarify():
    for b in range(n_batches):
        Y = L(X) # Oops! Should pass batch X[b]
```

Ollie on Y = L(X): would it really work if we did? dimensions still seem off just by looking at it, did not execute code, so not sure

In the TensorSensor visualization, notice that `input` is 3D and that the third dimension is shown on an angle, with an extra box to indicate more than two dimensions:

<table>
	<tr>
			<th width="37%">Visualization
				<th>Augmented exception message
	<tr><td><img src="images/torch-batch.svg" width="100%">
		<td><html>
<div class=exception>RuntimeError: size mismatch, m1: [15280 x 10], m2: [764 x 100] at /tmp/pip-req-build-as628lz5/aten/src/TH/generic/THTensorMath.cpp:41
Cause: @ on tensor operand self.W w/shape [100, 764] and operand input.T w/shape [764, 10, 20]</div>
</html>
</table>

To demonstrate TensorSensor's visualization for tensors beyond 3D, consider input instances that are images containing red, green, blue values for each input pixel. A common representation would be a `1 x d x 3` matrix for each image (`d` would be with times height of the image). For `n` images, we have an `n x d x 3` matrix. Now, add batching to that and we get an `n_batches x batch_size x d x 3` matrix.  The goal here is to illustrate the 4D visualization, so let's create a 4D matrix and then perform an illegal operation. (The `[:]` in `X[:]` prevents silent broadcasting so we get an exception.)

```
W = torch.rand(n_neurons,d)
b = torch.rand(n_neurons,1)
batch_size = 10
n_batches = n // batch_size
X = torch.rand(n_batches,batch_size,d,3)

with tsensor.explain():
    Y = W @ X[:].T + b
```

<table>
	<tr>
			<th width="37%">Visualization
				<th>Augmented exception message
	<tr><td><img src="images/torch-4D.svg" width="83%">
		<td><html>
<div class=exception>RuntimeError: size mismatch, m1: [45840 x 10], m2: [764 x 100] at /tmp/pip-req-build-as628lz5/aten/src/TH/generic/THTensorMath.cpp:41
Cause: @ on tensor operand W w/shape [100, 764] and operand X[:].T w/shape [3, 764, 10, 20]
</div>
</html>
</table>

For matrices with more than three dimensions, all dimensions are displayed at the bottom of the matrix box. In this case, the fourth dimension is displayed as "`...x3`".

Row and column vectors are matrices with one row and one column, respectively. These are also shown as light green but as horizontal or vertical rectangles. For example, let's create a column vector and attempt a dot product:

```
b = torch.rand(n_neurons,1)
with tsensor.clarify() as c:
    torch.dot(b, b)
```

The PyTorch dot product expects 1D not 2D matrices (even though one of the dimensions has size 1), so we get an exception. TensorSensor highlights the function and appropriate arguments:

<table>
	<tr>
			<th width="37%">Visualization
				<th>Augmented exception message
	<tr><td><img src="images/torch-1D.svg" width="53%">
		<td><html>
<div class=exception>RuntimeError: 1D tensors expected, got 2D, 2D tensors at /tmp/pip-req-build-as628lz5/aten/src/TH/generic/THTensorEvenMoreMath.cpp:83
Cause: torch.dot(b,b) tensor arg b w/shape [100, 1], arg b w/shape [100, 1]
</div>
</html>
</table>

row vecs look like: ...

1D looks like: ...

show something about what I rejected, including relative sizing.

<section title="Explaining non-erroneous tensor code">


explain

full AST

<section title="TensorSensor implementation Kung Fu">


	