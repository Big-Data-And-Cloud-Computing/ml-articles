<chapter title="How to visualize decision tree models"
         author={[Terence Parr](http://parrt.cs.usfca.edu) and [Prince Grover](https://www.linkedin.com/in/groverpr)}>


Decision trees are the fundamental building block of [gradient boosting machines](http://explained.ai/gradient-boosting/index.html) and [Random Forests](https://en.wikipedia.org/wiki/Random_forest)\symbol{tm}, probably the two most popular machine learning models for structured data.  Visualizing decision trees is a tremendous aid when learning these models and later, in practice, when interpreting models.  Unfortunately, current visualization packages are rudimentary and not immediately helpful to the novice. For example, we couldn't find a library that could visualize how decision nodes split up feature space. Our library could be the first.  It also appears uncommon for libraries to support visualizing a specific feature vector as it weaves down through a tree's decision nodes, as we could only find one image showing this (but we didn't exhaustively look through library APIs).

Terence has reached a point in his book on [machine learning book](https://mlbook.explained.ai/) (written with [Jeremy Howard](http://www.fast.ai/about/#jeremy)) where he needs to describe lots of decision trees. So, he and former [University of San Francisco MS in Data Science](https://www.usfca.edu/arts-sciences/graduate-programs/data-science) student Prince Grover teamed up to create a general package for [scikit-learn](https://github.com/scikit-learn/scikit-learn) decision tree visualization and model interpretation. This article demonstrates the results of this work, details the specific choices we made for visualization, and outlines the mashup of tools and techniques used in the implementation. The visualization software is part of a nascent Python machine learning library called [animl](https://github.com/parrt/animl).

We assume you're familiar with the basic mechanism of decision trees if you're interested in visualizing them, but let's start with a brief summary so that we're all using the same terminology.

<section title="Decision tree review">

A decision tree is a machine learning model based upon binary trees, trees with at most a left and right child.  A decision tree learns the relationship between feature vectors $\vec{x}$ and target values $y$ (in a training set) by examining and condensing training data into a binary tree of interior decision nodes and leaf prediction nodes.  (notation: vectors are in bold and scalars are in italics.)

Each leaf in the decision tree is responsible for making a specific prediction.  If this is a regression tree, the prediction is a value in the target space, such as price.  If this is a classifier tree, the prediction is an integer indicating the predicted target class, such as cancer or not-cancer. A decision tree carves up the feature space into groups of feature vectors that share similar target values and each leaf represents one of these groups.  For regression, "similar" means a low variance between target values and, for classification, "similar" means that most or all targets are of a single class.

Any path from the root of the decision tree to a specific $y$ leaf predictor passes through a series of (internal) decision nodes. Each decision node compares a single feature's value in $\vec{x}$, $x_i$, with a specific \first{split point} value learned during training. For example, in a model predicting apartment rent prices, decision nodes would test features such as the number of bedrooms and number of bathrooms.  In a classifier with discrete target values, decision nodes still compare numeric *feature* values. Most decision tree implementation's assume that all features are numeric, with all categorical variables [one hot encoded](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/), [binned](https://www.analyticsvidhya.com/blog/2015/11/easy-methods-deal-categorical-variables-predictive-modeling/), [label encoded](http://forums.fast.ai/t/to-label-encode-or-one-hot-encode/6057), etc...

To train a decision node, the model examines a subset of the training observations (or the full training set at the root). The node's feature and split point within that feature space are chosen during training to split the observations into left and right buckets (subsets). The left bucket has observations whose $x_i$ feature values are all less than the split point and the right bucket has observations whose $x_i$ is greater than the split point.  The goal is to pick a feature and split point in that feature space so that, within the left and right buckets, the observations have similar target values. (This selection process is generally done through exhaustive comparison of features and  feature values.) Tree construction proceeds recursively by creating decision nodes for the left bucket and the right bucket.  Given a bucket with suitably similar target values, the model creates a leaf node rather than a decision node. The leaf predicts the mean (regression) or most common target (classification).

<section title="The key elements of decision tree visualization">
	
Decision tree visualizations would optimally highlight the following important elements:

<ul>
	<li>Decision node feature vs target value distributions; i.e., how separable are the target values based upon the feature and a split point?
	<li>Decision node feature name
	<li>Decision node feature split value
	<li>Leaf node purity
	<li>Leaf node prediction value
	<li>Numbers of samples in decision and leaf nodes
	<li>How a specific feature vector is run down the tree to a leaf
</ul>

<section title="Gallery of decision tree visualizations">
	
Before digging into the previous state-of-the-art visualizations, we'd like to give a little spoiler to show what's possible. This section highlights some samples visualizations we built from scikit regression and classification decision trees on a few data sets. You can also check out the	
[full gallery](https://github.com/parrt/animl/tree/master/testing/samples) 
and [code to generate all samples](https://github.com/parrt/animl/blob/master/testing/gen_samples.py).

<table>
	<tr>
		<th width="50%"><th width="50%">
	<tr>
		<td>[WINE](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine) 3-class top-down orientation
		<td>[BREAST CANCER](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer) 2-class right-to-left
	<tr>
		<td>[<img src="images/icons/wine-TD-2-icon.png" width="100%">](images/wine-TD-2.png)
		<td>[<img src="images/icons/breast_cancer-LR-3-icon.png" width="100%">](images/breast_cancer-LR-3.png)
	<tr>
		<td>[IRIS](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris) 3-class with sample $\vec{x}$
		<td>[USER KNOWLEDGE RATING](https://archive.ics.uci.edu/ml/datasets/User+Knowledge+Modeling) 4-class
	<tr>
		<td>[<img src="images/icons/iris-TD-3-X-icon.png" width="100%">](images/iris-TD-3-X.png)
		<td>[<img src="images/icons/knowledge-LR-3-icon.png" width="100%">](images/knowledge-LR-3.png)
	<tr>
		<td>[DIGITS](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits) 10-class 
		<td>[DIABETES](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html) with sample $\vec{x}$
	<tr>
		<td>[<img src="images/icons/digits-LR-3-icon.png" width="100%">](images/digits-LR-3.png)
		<td>[<img src="images/icons/diabetes-TD-3-X-icon.png" width="100%">](images/diabetes-TD-3-X.png)	
	<tr>
		<td>[BOSTON](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) with sample $\vec{x}$
		<td>[SWEETS](http://mldata.org/repository/data/viewslug/ratings-of-sweets-sweetrs/) with sample $\vec{x}$
	<tr>
		<td>[<img src="images/icons/boston-TD-3-X-icon.png" width="100%">](images/boston-TD-3-X.png)
		<td>[<img src="images/icons/sweets-TD-3-X-icon.png" width="100%">](images/sweets-TD-3-X.png)
	<tr>
		<td>USER KNOWLEDGE RATING 4-class non-fancy
		<td>DIABETES non-fancy
	<tr>
		<td>[<img src="images/icons/knowledge-TD-4-simple-icon.png" width="100%">](images/knowledge-TD-4-simple.png)
		<td>[<img src="images/icons/boston-LR-5-X-simple-icon.png" width="100%">](images/boston-LR-5-X-simple.png)

</table>	

<section title="A comparison to previous state-of-the-art visualizations">
	
If you do a web search for "visualizing decision trees" you will quickly find a **Python** solution provided by the awesome scikit folks: [sklearn.tree.export_graphviz](http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html).  With more work, you can find visualizations for **R** and even **SAS** and **IBM's Watson**. In this section, we collect the various decision tree visualizations we could find and compare them to the visualizations made by our `animl` library. We give a more detailed discussion of our visualizations in the next section.


Let's start with the [default scitkit visualization](http://scikit-learn.org/stable/modules/tree.html) of a decision tree on the [IRIS](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris) data set (click on images to enlarge).

<table>
	<tr>
		<th width="50%">
		<th width="50%">
			<tr>
				<td>Default scikit IRIS visualization
				<td>Our `animl` IRIS visualization
	<tr>
		<td>[<img src="images/iris-scikit.png" width="100%">](images/iris-scikit.png)
		<td>[<img src="images/iris-TD-5.png" width="100%">](images/iris-TD-5.png)
</table>
		
The scikit tree does a good job of representing the tree structure, but we have a few quibbles.  The colors aren't the best and it's not immediately obvious why some of the nodes are colored and some aren't.  If the colors represent predicted class for this classifier, one would think just the leaves would be colored because only leaves have predictions.  Including the gini coefficient costs space and doesn't really help the beginners to interpret trees. The count of samples of the  various target classes in each node is somewhat useful, though, a histogram would be even better. A target class color legend would be nice.  Finally, using true and false as the edge labels isn't as clear as, say, labels $<$ and $\ge$. The most obvious difference is that our decision nodes show feature distributions as overlapping stacked-histograms, one histogram per target class. Also, our leaf size is proportional to the number of samples in that leaf.

Scikit uses the same visualization approach for decision tree regressors. For example, here is scikit's visualization using the [BOSTON](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) data set, with `animl`'s version for comparison (click to enlarge images):

<table>
	<tr>
		<th width="50%">
		<th width="50%">
			<tr>
				<td>Default scikit BOSTON visualization
				<td>Our `animl` BOSTON visualization
	<tr>
		<td>[<img src="images/boston-scikit.png" width="100%">](images/boston-scikit.png)
		<td>[<img src="images/boston-TD-3.png" width="100%">](images/boston-TD-3.png)
</table>

In the scikit tree, it's not immediately clear what the use of color implies, but after studying the image, darker images indicate higher predicted target values. As before, our decision nodes show the feature space distribution, this time using a feature versus target value scatterplot.  The leaves use strip plots to show the target value distribution; leaves with more dots naturally have a higher number of samples.

**R** programmers also have access to a package for [visualizing decision trees](http://blog.revolutionanalytics.com/2013/06/plotting-classification-and-regression-trees-with-plotrpart.html), which gives similar results to scikit but with nice edge labels:

[<img src="images/R-tree.png" width="40%">](images/R-tree.png)

If you dig really hard, you will find that **SAS** and **IBM** provide (non-Python-based) decision tree visualizations.  Starting with SAS, we see that their decision nodes include a bar chart related to the node's sample target values and other details:
	
<table>
	<tr>
		<th width="50%">
		<th width="50%">
			<tr>
				<td>SAS visualization
				<td>SAS visualization (best image quality we could find with numeric features)
	<tr>
		<td>[<img src="images/sas-tree.png" width="100%">](images/sas-tree.png)
		<td>[<img src="images/sas-tree2.jpeg" width="100%">](images/sas-tree2.jpeg)
</table>


Indicating the size of the left and right buckets via edge width is a nice touch. But, those bar charts are hard to interpret because they have no X axis.  Decision nodes testing categorical variables (left image) have exactly one bar per category so they must represent simple category counts, rather than feature distributions. For numeric features (right image), SAS decision nodes show a histogram of either target  or feature space (we can't tell from the image). SAS node bar charts / histograms appear to illustrate just target values, which tells us nothing about how the feature space was split.

The SAS tree on the right appears to highlight a path through the decision tree for a specific unknown feature vector, but we couldn't find any other examples from other tools and libraries.  The ability to visualize a specific vector run down the tree does not seem to be generally available.

Moving on to IBM software, here is a nice visualization, that also shows decision node category counts as bar charts, from [IBM's Watson analytics](https://www.ibm.com/support/knowledgecenter/en/SS4QC9/com.ibm.solutions.wa_an_overview.2.0.0.doc/wa_discover_viz_expl_insigths_dec_tree.html) (on the [TITANIC](https://www.kaggle.com/c/titanic/data) data set):

[<img src="images/ibm-tree.png" width="60%">](images/ibm-tree.png)

IBM's earlier **SPSS** product also had decision tree visualizations:

<table>
	<tr>
		<th width="50%">
		<th width="50%">
			<tr>
				<td>SPSS visualization
				<td>SPSS visualization
	<tr>
		<td>[<img src="images/spss-tree.png" width="100%">](images/spss-tree.png)
		<td>[<img src="images/spss-tree2.png" width="100%">](images/spss-tree2.png)
</table>

These SPSS decision nodes seem to give the same SAS-like bar chart of sample target class counts.

All of the visualizations we encountered from the major players were useful, but we were most inspired by the eye-popping visualizations in [A visual introduction to machine learning](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/), which shows an (animated) decision tree like this:

[<img src="images/vizml-tree.png" width="75%">](images/vizml-tree.png)

This visualization has three unique characteristics over previous work, aside from the animation:

<ul>
	<li>the decision nodes show how the feature space is split
	<li>the split points for decision nodes are shown visually (as a wedge) in the distribution
	<li>the leaf size is proportional to the number of samples in that leaf
</ul>

While that visualization is a hardcoded animation for educational purposes, it points in the right direction.

<section title="Our decision tree visualizations">
	
Other than the educational animation in [A visual introduction to machine learning](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/), we couldn't find a decision tree visualization package that illustrates how the feature space is split up at  decision nodes.  This is the critical operation performed during decision tree model training and is what newcomers should focus on, so we'll start by examining decision node visualizations for both classification and regression trees. 

<subsection title="Visualizing feature-target space">

Training of a decision node chooses feature $x_i$ and split value within $x_i$ feature space to group similar target values into two buckets.  Just to be clear, training involves examining the relationship between features and target values. Unless decision nodes show feature-target space in some way, the viewer cannot see how and why training arrived at the split value. To highlight how decision nodes carve up the feature space, we trained a regressor and classifier with a single feature (here is the [code to generate images](https://github.com/parrt/animl/blob/master/testing/paper_examples.py)).  Here's a regressor decision tree trained on BOSTON data, with node ID labeling turned on for discussion purposes here:

[<img src="images/boston-TD-AGE.png" width="100%">](images/boston-TD-AGE.png)

describe wedge,  vertical and horizontal dashed lines

All decision nodes are restricted to the single AGE feature and please note that our visualization forces the same X axis range for all nodes testing the same feature, leaving blank regions rather than zooming in. As we descend through decision nodes, the sample AGE values are boxed into narrower and narrower regions.  Combining the AGE feature-target space (regions) from two siblings yields the parent's feature-target space. For example, combining the AGE regions in nodes 1 and 8, yields the node 0 feature-target space and combining the AGE regions from nodes 9 and 12 yields the node 8 feature-target space. The prediction leaves are not very pure and using a single variable leads to poor model, but it demonstrates how decision trees carve up feature space nicely.

While a decision tree implementation is virtually identical for both classifier and regressor decision trees, the way we interpret them is very different so our visualizations are distinct for the two cases.  For a regressor, showing feature-target space is best done with a scatterplot of feature versus target.  For classifier, however, the target is a category rather than a number and so we chose to illustrate feature-target space using histograms as an indicator of feature space distributions.  Here's a classifier tree trained on the USER KNOWLEDGE data, again with a single feature (called PEG) and with nodes labeled for discussion purposes:

[<img src="images/knowledge-TD-PEG.png" width="100%">](images/knowledge-TD-PEG.png)

Ignoring color, the histogram shows the PEG feature space distribution.  Adding color, gives us an indication of the relationship between feature space and target class (feature-target space). For example, in node 0, we can see that samples with `very_low` target class are clustered at the low end of PEG feature space and samples with `High` target class are clustered at the high-end. As with the regressor, the feature space of a left child is everything to the left of the parents split point in the same  feature space; similarly for the right child.  For example, combining the histograms of nodes 9 and 12 yields the histogram of node 8. We force the X axis range to be the same for all PEG decision nodes. In this way, lower decision nodes clearly box in narrower regions that are more and more pure.

We use a stacked histogram so that overlap is clear in the feature space between samples with different target classes.  Note that the height in the Y axis of the stacked histogram is the total number of samples from all classes; multiple class counts are stacked on top of each other. 

When there are more than four or five classes, the stacked histograms are difficult to read and so we recommend setting the histogram type parameter to `bar` not `barstacked` in this case.  With high cardinality target categories, the overlapping distributions are harder to visualize and things break down, so we set a limit of 10 target classes. Here's a shallow tree example using the 10-class DIGITS data set using non-stacked histograms:

[<img src="images/digits-TD-2.png" width="65%">](images/digits-TD-2.png)

<subsection title="It's all about the details">

Thus far we've skipped over many of the visual cues and details that we  obsessed over during construction of the library and so we hit the key elements here.

Our classifier tree visualizations use node size to give visual cues about the number of samples associated with each node.  Histograms get proportionally shorter as the number of samples in the node decrease and leaf node diameters get smaller.  The feature space (horizontal axis) is always the same width and the same range for a given feature, which makes it much easier to compare the feature-target spaces of different nodes. The bars of all histograms are the same width in pixels.

<img src="images/knowledge-dec-node.png" width="35%">

We use a pie chart for classifier leaves, despite their bad reputation.  For the purpose of indicating purity, the viewer only needs an indication of whether there is a single strong majority category. The viewer does not need to see the exact relationship between elements of the pie chart, which is one key area where pie charts fail. The color of the pie chart majority slice gives the leaf prediction. 

<img src="images/knowledge-leaf.png" width="8%">

Turning to regressor trees now, we make sure that the target (vertical) axis of all decision nodes is the same height and the same range to make comparing nodes easier. Regressor feature space (horizontal axis) is always the same width and the same range for a given feature.  We set a low alpha for all scatterplot dots so that increased target value density corresponds to darker color.  Horizontal dashed lines indicate the target mean for the left and right buckets; a vertical dashed line indicates the split point in feature space.

<img src="images/boston-dec-node.png" width="35%">


Regressor leaves also show the same range vertically for the target space, but leaves are a bit taller than decision nodes so it's easier to identify nodes with high or low predictions. We use a strip plot rather than, say, a box plot because the strip plot shows the distribution explicitly and implicitly shows the number of samples by the number of dots. (We also write out the number of samples in text for leaves.) The leaf prediction is the distribution center of mass (mean) of the strip plot, which we highlight with a dashed line.

<img src="images/boston-leaf.png" width="25%">



There are a number of miscellaneous details that we think improve the quality of the diagrams. Classifiers include a legend and all colors were handpicked from colorblind safe palletes, one handpicked pallete per number of target categories (2 through 10).  We use a gray rather than black for text because it's easier on the eyes. Lines are hairlines and we draw outlines of bars in bar charts and slices in pie charts.

<subsection title="Visualizing interpretation of a single observation">

orange wedge to the left or right of the black wedge, split value. gives visual cues of why the left or right child path was taken.  features used during decision-making are highlighted.  nodes in the path are highlighted with dashed boxes.  edges are orange and thicker. feature vector displayed near the leaf predictor.

subtleties: highlight the edges of paths taken, highlight the decision nodes and leaves. highlight the features used to make the decision.  if too many features, then subset to just those features used. difference depending on whether it's left to right or top down. orange wedge showing left/right of split point.
	
	KNOWLEDGE
	
	[<img src="images/icons/knowledge-TD-3-X-icon.png" width="100%">](images/knowledge-TD-3-X.png)

	[DIABETES](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes)

	[<img src="images/icons/diabetes-TD-3-X-icon.png" width="100%">](images/diabetes-TD-3-X.png)

<subsection title="Left-to-right orientation">

	Some users have a preference for left to right instead of top-down layout and sometimes the nature of the tree simply flows better left to right. Sample feature vectors can still be run down the tree with the left to right orientation. Here are some examples (click on the images to enlarge):
	
<table>
	<tr>
		<th width="50%"><th width="50%">
	<tr>
		<td>WINE
		<td>DIABETES
	<tr>
		<td>[<img src="images/icons/wine-LR-3-icon.png" width="100%">](images/wine-LR-3.png)
		<td>[<img src="images/icons/diabetes-LR-3-icon.png" width="100%">](images/diabetes-LR-3.png)
	<tr>
		<td>WINE with sample $\vec{x}$
		<td>DIABETES with sample $\vec{x}$
	<tr>
		<td>[<img src="images/icons/wine-LR-2-X-icon.png" width="100%">](images/wine-LR-2-X.png)
		<td>[<img src="images/icons/diabetes-LR-2-X-icon.png" width="100%">](images/diabetes-LR-2-X.png) 
</table>
	
<subsection title="Simplified non-fancy layout">

get an overview of the tree and where all of the weight falls, which nodes appear and less on the decision nodes.  you can see very large trees but you have to do some scrolling and zooming.
	
	[<img src="images/icons/knowledge-TD-15-X-simple-icon.png" width="55%">](images/knowledge-TD-15-X-simple.png)

For regressors, it looks better left to right, otherwise it is too wide.
	
	[<img src="images/icons/boston-LR-5-X-simple-icon.png" width="55%">](images/boston-LR-5-X-simple.png)

<section title="Code sample">
		
```
regr = tree.DecisionTreeRegressor(max_depth=max_depth)
boston = load_boston()
regr = regr.fit(boston.data, boston.target)
```

```
st = dtreeviz(regr, boston.data, boston.target, target_name='price',
              feature_names=boston.feature_names)
```

```
g = graphviz.Source(st, format='pdf')
g.render(directory=".", filename="boston.pdf", view=False, cleanup=True)
```

```
g = graphviz.Source(st, format='pdf')
g.view()
```

```
X = boston.data[np.random.randint(0, len(boston.data)),:]

st = dtreeviz(regr, boston.data, boston.target, target_name='price',
              feature_names=boston.feature_names,
              X=X)
```

for classifier we need the class names too.

<section title="Our implementation">
	
	shadow tree
	
	graphviz/dot

	matplotlib

	load svg was issue

	then must parse svg to get size

	future: bottom-justify histograms in classifier trees. some wedge labels overlap with axis. thicken incoming edges for nodes with lots of samples.
	
<section title="What we tried and rejected">

classifier decision nodes

	<img src="images/kde.png" width="50%">

	<img src="images/kde-leaf.png" width="15%">
	
	<img src="images/bubble.png" width="70%">

regression leaf nodes		

	<img src="images/dual-leaf.png" width="15%">
		
	<img src="images/non-strip-plot.png" width="30%">
		
<section title="Lessons learned">

We are definitely not visualization aficionados, but for this specific problem we banged on it until we got effective diagrams.

	there are lots of visual effects one can choose from to visualize data: color, line thickness, line style, different kinds of plots, size (area, length, graph height, ...), alpha, text styles (color, font, bold, italics, size), graph annotations, visual flow.  Everything has to be for a reason don't just use color because colors are nice. they have to mean something.  In Tufte's seminar I learned that you can pack a lot of information into a rich diagram; humans can deal with it, but it can't be a mishmash.
	
	as our subtlety list shows, there's more to it.  same axis, same scale etc.