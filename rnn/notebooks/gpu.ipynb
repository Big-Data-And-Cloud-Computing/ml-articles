{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on GPU with vectorized mini-batch SGD\n",
    "\n",
    "This notebook is part of article [Explaining RNNs without neural networks](https://explained.ai/rnn/index.html) and notebook [prep.ipynb](prep.ipynb) should be run before this notebook as it needs files: `data/X.pkl` and `data/y.pkl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "from support import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "with open('data/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TESTING SUBSAMPLE\n",
    "idx = list(np.random.randint(0,len(X),size=2000))\n",
    "X = np.array(X)[idx].tolist()\n",
    "y = np.array(y)[idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_matrix(X, max_len, vocab, verbose=False):\n",
    "    X_onehot = torch.zeros((len(X),max_len,len(vocab)), dtype=torch.float64)\n",
    "    for i,x in enumerate(X):\n",
    "        pad = max_len - len(x)\n",
    "        for j,c in enumerate(x):\n",
    "            X_onehot[i, j+pad, ctoi[c]] = 1\n",
    "        if verbose: print(x); print(X_onehot[i].T, \"\\n\")\n",
    "    return X_onehot.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X_onehot, max_len:int, vocab:dict):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "    H = torch.zeros(nhidden, len(X_onehot), device=device, dtype=torch.float64, requires_grad=False)\n",
    "    for j in range(max_len):\n",
    "        x_step_t = X_onehot[:,j].T\n",
    "        H = W.mm(H) + U.mm(x_step_t)\n",
    "        H = torch.tanh(H)        \n",
    "    o = V.mm(H)\n",
    "    o = o.T # make it batch_size x nclasses\n",
    "    o = softmax(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just some matrices. First, set up hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, dtype=torch.long) # keep these on the CPU\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ctoi = getvocab(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,688 training records, batch size 32, 29 features (chars), 18 target languages, state is 100-vector\n"
     ]
    }
   ],
   "source": [
    "nhidden = 100\n",
    "batch_size = 32\n",
    "\n",
    "n = len(X_train)\n",
    "\n",
    "nbatches = n // batch_size\n",
    "n = nbatches * batch_size\n",
    "X_train = X_train[0:n]\n",
    "y_train = y_train[0:n]\n",
    "vocab, ctoi = getvocab(X)\n",
    "max_len = get_max_len(X)\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(torch.unique(y_train))\n",
    "\n",
    "print(f\"{n:,d} training records, batch size {batch_size}, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using pure SGD, one record used to compute gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  2.0549 accur 0.591 | train loss  1.2205 accur 0.641 | valid loss  1.3652 accur 0.622\n",
      "Epoch:   2 accum loss  1.2257 accur 0.666 | train loss  1.1552 accur 0.643 | valid loss  1.3194 accur 0.618\n",
      "Epoch:   3 accum loss  1.0749 accur 0.692 | train loss  0.9463 accur 0.707 | valid loss  1.1151 accur 0.678\n",
      "Epoch:   4 accum loss  0.9730 accur 0.718 | train loss  0.8879 accur 0.733 | valid loss  1.0785 accur 0.703\n",
      "Epoch:   5 accum loss  0.9183 accur 0.733 | train loss  0.8850 accur 0.745 | valid loss  1.0620 accur 0.712\n",
      "Epoch:   6 accum loss  0.9086 accur 0.735 | train loss  0.8094 accur 0.759 | valid loss  1.0026 accur 0.726\n",
      "Epoch:   7 accum loss  0.8528 accur 0.746 | train loss  0.7823 accur 0.769 | valid loss  1.0105 accur 0.731\n",
      "Epoch:   8 accum loss  0.8276 accur 0.755 | train loss  0.7563 accur 0.778 | valid loss  1.0034 accur 0.742\n",
      "Epoch:   9 accum loss  0.8026 accur 0.761 | train loss  0.7932 accur 0.768 | valid loss  1.0518 accur 0.730\n",
      "Epoch:  10 accum loss  0.7697 accur 0.770 | train loss  0.7545 accur 0.772 | valid loss  1.0104 accur 0.735\n",
      "Epoch:  11 accum loss  0.7478 accur 0.775 | train loss  0.7789 accur 0.779 | valid loss  1.0707 accur 0.726\n",
      "Epoch:  12 accum loss  0.7366 accur 0.777 | train loss  0.6675 accur 0.807 | valid loss  0.9719 accur 0.765\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 24s, sys: 15.6 s, total: 2min 39s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden,    nhidden,   device=device, dtype=torch.float64, requires_grad=True)\n",
    "U = torch.randn(nhidden,  nfeatures, device=device, dtype=torch.float64, requires_grad=True) # embed one-hot char vec\n",
    "V = torch.randn(nclasses, nhidden,   device=device, dtype=torch.float64, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "# Let's compute the big 3D one hot matrix for all examples so we don't re-create\n",
    "# four batches all the time; might push data back and forth between CPU and GPU\n",
    "X_train_onehot = onehot_matrix(X_train, max_len, vocab)\n",
    "X_valid_onehot = onehot_matrix(X_valid, max_len, vocab)\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.005, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total = 0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        batch_X = X_train_onehot[p:p+batch_size]\n",
    "        batch_y = y_train[p:p+batch_size]\n",
    "        H = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)\n",
    "        for t in range(max_len):\n",
    "            x_step_t = batch_X[:,t].T # make it len(vocab) x batch_size\n",
    "            H = W.mm(H) + U.mm(x_step_t)\n",
    "            H = torch.tanh(H)\n",
    "        o = V.mm(H)\n",
    "        o = o.T # make it batch_size x nclasses\n",
    "        o = softmax(o)\n",
    "        loss = cross_entropy(o, batch_y)\n",
    "#         print(loss.item())\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==batch_y\n",
    "        epoch_training_accur += torch.sum(correct)\n",
    "        total += len(batch_y)\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    epoch_training_loss /= nbatches\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train_onehot, max_len, vocab)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_train\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid_onehot, max_len, vocab)\n",
    "        valid_loss = cross_entropy(o, y_valid).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_valid\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing on 80% training from full data set using a GeForce RTX 2080 Ti with 11G RAM.\n",
    "    \n",
    "```\n",
    "CPU times: user 36.8 s, sys: 1.19 s, total: 38 s\n",
    "Wall time: 37.9 s\n",
    "```\n",
    "\n",
    "Basically the same speed as the vectorized running on the CPU, but our data set is pretty small and is likely dominated by all of the metrics I'm computing.  When I bump batch size to 300, I get a time of 17s vs 42s. Training accuracy is much better too as is validation. Hmm... LeCun and others report that validation error will suffer. Oh well. Bigger is better for this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
