{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on GPU with vectorized mini-batch SGD\n",
    "\n",
    "This notebook is part of article [Explaining RNNs without neural networks](https://explained.ai/rnn/index.html) and notebook [prep.ipynb](prep.ipynb) should be run this notebook as it needs files: `data/X.pkl` and `data/y.pkl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "from support import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "with open('data/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TESTING SUBSAMPLE\n",
    "idx = list(np.random.randint(0,len(X),size=2000))\n",
    "X = np.array(X)[idx].tolist()\n",
    "y = np.array(y)[idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_matrix(X, max_len, vocab, verbose=False):\n",
    "    X_onehot = torch.zeros((len(X),max_len,len(vocab)), dtype=torch.float64)\n",
    "    for i,x in enumerate(X):\n",
    "        pad = max_len - len(x)\n",
    "        for j,c in enumerate(x):\n",
    "            X_onehot[i, j+pad, ctoi[c]] = 1\n",
    "        if verbose: print(x); print(X_onehot[i].T, \"\\n\")\n",
    "    return X_onehot.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X:Sequence[Sequence], max_len:int, vocab:dict):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "    X_onehot = onehot_matrix(X, max_len, vocab)\n",
    "    H = torch.zeros(nhidden, len(X), device=device, dtype=torch.float64, requires_grad=False)\n",
    "    for j in range(max_len):\n",
    "        x_step_t = X_onehot[:,j].T\n",
    "        H = W.mm(H) + U.mm(x_step_t)\n",
    "        H = torch.tanh(H)        \n",
    "    o = V.mm(H)\n",
    "    o = o.T # make it batch_size x nclasses\n",
    "    o = softmax(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just some matrices. First, set up hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, dtype=torch.long) # keep these on the CPU\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ctoi = getvocab(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,688 training records, batch size 32, 29 features (chars), 18 target languages, state is 100-vector\n"
     ]
    }
   ],
   "source": [
    "nhidden = 100\n",
    "batch_size = 32\n",
    "\n",
    "n = len(X_train)\n",
    "\n",
    "nbatches = n // batch_size\n",
    "n = nbatches * batch_size\n",
    "X_train = X_train[0:n]\n",
    "y_train = y_train[0:n]\n",
    "vocab, ctoi = getvocab(X)\n",
    "max_len = get_max_len(X)\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(torch.unique(y_train))\n",
    "\n",
    "print(f\"{n:,d} training records, batch size {batch_size}, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using pure SGD, one record used to compute gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  1.9942 accur 0.610 | train loss  1.1132 accur 0.698 | valid loss  1.2944 accur 0.668\n",
      "Epoch:   2 accum loss  1.1725 accur 0.690 | train loss  0.9373 accur 0.734 | valid loss  1.1658 accur 0.696\n",
      "Epoch:   3 accum loss  1.0130 accur 0.721 | train loss  0.8740 accur 0.751 | valid loss  1.1470 accur 0.707\n",
      "Epoch:   4 accum loss  0.8933 accur 0.745 | train loss  0.7819 accur 0.771 | valid loss  1.0857 accur 0.720\n",
      "Epoch:   5 accum loss  0.8334 accur 0.762 | train loss  0.7792 accur 0.768 | valid loss  1.0929 accur 0.715\n",
      "Epoch:   6 accum loss  0.7926 accur 0.769 | train loss  0.6888 accur 0.796 | valid loss  1.0152 accur 0.737\n",
      "Epoch:   7 accum loss  0.7587 accur 0.778 | train loss  0.7170 accur 0.786 | valid loss  1.0153 accur 0.724\n",
      "Epoch:   8 accum loss  0.7503 accur 0.778 | train loss  0.6634 accur 0.798 | valid loss  1.0028 accur 0.729\n",
      "Epoch:   9 accum loss  0.7278 accur 0.783 | train loss  0.6535 accur 0.801 | valid loss  0.9889 accur 0.732\n",
      "Epoch:  10 accum loss  0.6874 accur 0.794 | train loss  0.6229 accur 0.811 | valid loss  0.9805 accur 0.742\n",
      "Epoch:  11 accum loss  0.6994 accur 0.788 | train loss  0.6619 accur 0.802 | valid loss  1.0470 accur 0.729\n",
      "Epoch:  12 accum loss  0.6774 accur 0.794 | train loss  0.6909 accur 0.801 | valid loss  1.0708 accur 0.724\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.7 s, sys: 1.17 s, total: 39.8 s\n",
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden,    nhidden,   device=device, dtype=torch.float64, requires_grad=True)\n",
    "U = torch.randn(nhidden,  nfeatures, device=device, dtype=torch.float64, requires_grad=True) # embed one-hot char vec\n",
    "V = torch.randn(nclasses, nhidden,   device=device, dtype=torch.float64, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.005, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total = 0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        batch_X = X_train[p:p+batch_size]\n",
    "        batch_y = y_train[p:p+batch_size]\n",
    "        batch_X_onehot = onehot_matrix(batch_X, max_len, vocab)\n",
    "        H = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)\n",
    "        for t in range(max_len):\n",
    "            x_step_t = batch_X_onehot[:,t].T # make it len(vocab) x batch_size\n",
    "            H = W.mm(H) + U.mm(x_step_t)\n",
    "            H = torch.tanh(H)\n",
    "        o = V.mm(H)\n",
    "        o = o.T # make it batch_size x nclasses\n",
    "        o = softmax(o)\n",
    "        loss = cross_entropy(o, batch_y)\n",
    "#         print(loss.item())\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==batch_y\n",
    "        epoch_training_accur += torch.sum(correct)\n",
    "        total += len(batch_y)\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    epoch_training_loss /= nbatches\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train, max_len, vocab)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_train\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid, max_len, vocab)\n",
    "        valid_loss = cross_entropy(o, y_valid).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_valid\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing on 80% training from full data set using a GeForce RTX 2080 Ti with 11G RAM.\n",
    "    \n",
    "```\n",
    "CPU times: user 36.8 s, sys: 1.19 s, total: 38 s\n",
    "Wall time: 37.9 s\n",
    "```\n",
    "\n",
    "Basically the same speed as the vectorized running on the CPU, but our data set is pretty small and is likely dominated by all of the metrics I'm computing.  When I bump batch size to 300, I get a time of 17s vs 42s. Training accuracy is much better too as is validation. Hmm... LeCun and others report that validation error will suffer. Oh well. Bigger is better for this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
