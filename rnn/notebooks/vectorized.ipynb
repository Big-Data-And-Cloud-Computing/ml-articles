{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using vectorized mini-batch SGD\n",
    "\n",
    "This notebook is part of article [Explaining RNNs without neural networks](https://explained.ai/rnn/index.html) and notebook [prep.ipynb](prep.ipynb) should be run this notebook as it needs files: `data/X.pkl` and `data/y.pkl`.\n",
    "\n",
    "Instead of processing batch one record at a time from time 1 to time len(word), process all time steps t across all batch records at once, then proceed to time step (char index) t+1.  This allows us to vectorize and perform each time step in parallel.  We effectively remove a loop.\n",
    "\n",
    "But, it means we must pad to have same length in batch. We pad on left so the zero vectors are ignored to get same answer as record-by-record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "from support import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "with open('data/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TESTING SUBSAMPLE\n",
    "idx = list(np.random.randint(0,len(X),size=2000))\n",
    "X = np.array(X)[idx].tolist()\n",
    "y = np.array(y)[idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_matrix(X, max_len, vocab, verbose=False):\n",
    "    X_onehot = torch.zeros(len(X),max_len,len(vocab), dtype=torch.float64)\n",
    "    for i,x in enumerate(X):\n",
    "        pad = max_len - len(x)\n",
    "        for j,c in enumerate(x):\n",
    "            X_onehot[i, j+pad, ctoi[c]] = 1\n",
    "        if verbose: print(x); print(X_onehot[i].T, \"\\n\")\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X:Sequence[Sequence], max_len:int, vocab:dict):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "    X_onehot = onehot_matrix(X, max_len, vocab)\n",
    "    h = torch.zeros(nhidden, len(X), dtype=torch.float64, requires_grad=False)\n",
    "    for j in range(max_len):\n",
    "        x_step_t = X_onehot[:,j].T\n",
    "        h = W.mm(h) + U.mm(x_step_t)\n",
    "        h = torch.relu(h)        \n",
    "    o = V.mm(h)\n",
    "    o = o.T # make it batch_size x nclasses\n",
    "    o = softmax(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just some matrices. First, set up hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ctoi = getvocab(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(c) -> torch.tensor:\n",
    "    v = torch.zeros((len(vocab),1), dtype=torch.float64)\n",
    "    v[ctoi[c]] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with trivial data set\n",
    "\n",
    "Set TESTING=True to test vs full X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING = False\n",
    "\n",
    "nhidden = 100\n",
    "batch_size = 32\n",
    "\n",
    "if TESTING:\n",
    "    nhidden = 2\n",
    "    batch_size = 2\n",
    "\n",
    "    X_train = [['a','b'],['c','d','e'], # batch 1\n",
    "               ['f'],['c','a'], # batch 2\n",
    "               ['e']] # strip\n",
    "    y_train = [0,2,1,1,2]\n",
    "\n",
    "    X_valid = X_train\n",
    "    y_valid = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,688 training records, batch size 32, 29 features (chars), 18 target languages, state is 100-vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "n = len(X_train)\n",
    "\n",
    "nbatches = n // batch_size\n",
    "n = nbatches * batch_size\n",
    "X_train = X_train[0:n]\n",
    "y_train = y_train[0:n]\n",
    "vocab, ctoi = getvocab(X_train)\n",
    "max_len = get_max_len(X_train)\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(torch.unique(torch.tensor(y_train)))\n",
    "\n",
    "print(f\"{n:,d} training records, batch size {batch_size}, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['h', 'a', 'd', 'd', 'a', 'd'], ['b', 'o', 'u', 'c', 'h', 'a', 'r', 'd']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_onehot = onehot_matrix(X_train, max_len, vocab, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With verbose and trivial X_train we get:\n",
    "\n",
    "```\n",
    "tensor([[[0., 0., 0., 0., 0., 0.],\n",
    "         [1., 0., 0., 0., 0., 0.],\n",
    "         [0., 1., 0., 0., 0., 0.]],\n",
    "\n",
    "        [[0., 0., 1., 0., 0., 0.],\n",
    "         [0., 0., 0., 1., 0., 0.],\n",
    "         [0., 0., 0., 0., 1., 0.]],\n",
    "\n",
    "        [[0., 0., 0., 0., 0., 0.],\n",
    "         [0., 0., 0., 0., 0., 0.],\n",
    "         [0., 0., 0., 0., 0., 1.]],\n",
    "\n",
    "        [[0., 0., 0., 0., 0., 0.],\n",
    "         [0., 0., 1., 0., 0., 0.],\n",
    "         [1., 0., 0., 0., 0., 0.]]], dtype=torch.float64)\n",
    "```\n",
    "\n",
    "With `X_onehot.shape` = [4, 3, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using vectorized minibatch SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  1.4745 accur 0.569 | train loss  1.1934 accur 0.634 | valid loss  1.1377 accur 0.658\n",
      "Epoch:   2 accum loss  1.0692 accur 0.678 | train loss  0.9388 accur 0.718 | valid loss  0.9355 accur 0.728\n",
      "Epoch:   3 accum loss  0.9074 accur 0.724 | train loss  0.9142 accur 0.724 | valid loss  0.9444 accur 0.731\n",
      "Epoch:   4 accum loss  0.8244 accur 0.747 | train loss  0.7658 accur 0.762 | valid loss  0.8208 accur 0.760\n",
      "Epoch:   5 accum loss  0.7764 accur 0.758 | train loss  0.7459 accur 0.768 | valid loss  0.8090 accur 0.764\n",
      "Epoch:   6 accum loss  0.7517 accur 0.764 | train loss  0.6901 accur 0.783 | valid loss  0.7694 accur 0.767\n",
      "Epoch:   7 accum loss  0.7202 accur 0.773 | train loss  0.6766 accur 0.786 | valid loss  0.7518 accur 0.777\n",
      "Epoch:   8 accum loss  0.7147 accur 0.772 | train loss  0.6585 accur 0.795 | valid loss  0.7789 accur 0.771\n",
      "Epoch:   9 accum loss  0.7048 accur 0.783 | train loss  0.6661 accur 0.789 | valid loss  0.7570 accur 0.776\n",
      "Epoch:  10 accum loss  0.6936 accur 0.782 | train loss  0.6446 accur 0.798 | valid loss  0.7865 accur 0.770\n",
      "Epoch:  11 accum loss  0.6876 accur 0.784 | train loss  0.6233 accur 0.808 | valid loss  0.7377 accur 0.782\n",
      "Epoch:  12 accum loss  0.6520 accur 0.794 | train loss  0.6086 accur 0.809 | valid loss  0.7424 accur 0.778\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 50s, sys: 13.7 s, total: 4min 4s\n",
      "Wall time: 44.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden, nhidden,   dtype=torch.float64, requires_grad=True)\n",
    "U = randn(nhidden,     nfeatures, dtype=torch.float64, requires_grad=True) # embed one-hot char vec\n",
    "V = randn(nclasses,    nhidden,   dtype=torch.float64, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.01, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total = 0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        batch_X = X_train[p:p+batch_size]\n",
    "        batch_y = y_train[p:p+batch_size]\n",
    "        batch_X_onehot = onehot_matrix(batch_X, max_len, vocab)\n",
    "        H = torch.zeros(nhidden, batch_size, dtype=torch.float64, requires_grad=False)\n",
    "        for t in range(max_len):\n",
    "            x_step_t = batch_X_onehot[:,t].T # make it len(vocab) x batch_size\n",
    "            H = W.mm(H) + U.mm(x_step_t)\n",
    "            H = torch.relu(H)\n",
    "        o = V.mm(H)\n",
    "        o = o.T # make it batch_size x nclasses\n",
    "        o = softmax(o)\n",
    "        loss = cross_entropy(o, batch_y)\n",
    "#         print(loss.item())\n",
    "        correct = torch.argmax(o, dim=1)==batch_y\n",
    "        epoch_training_accur += torch.sum(correct)\n",
    "        total += len(batch_y)\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    epoch_training_loss /= nbatches\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train, max_len, vocab)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==torch.tensor(y_train)\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid, max_len, vocab)\n",
    "        valid_loss = cross_entropy(o, y_valid).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==torch.tensor(y_valid)\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing on 80% training from full data set:\n",
    "\n",
    "```\n",
    "CPU times: user 3min 50s, sys: 13.7 s, total: 4min 4s\n",
    "Wall time: 44.9 s\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
