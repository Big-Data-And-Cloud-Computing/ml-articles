{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using mini-batch SGD, multiple records used to compute gradient\n",
    "\n",
    "This notebook is part of article [Explaining RNNs without neural networks](https://explained.ai/rnn/index.html) and notebook [prep.ipynb](prep.ipynb) should be run this notebook as it needs files: `data/X.pkl` and `data/y.pkl`.\n",
    "\n",
    "Still w/o vectorization, we train one full record at a time; we just do a batch of words before computing gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "from support import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "with open('data/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TESTING SUBSAMPLE\n",
    "idx = list(np.random.randint(0,len(X),size=2000))\n",
    "X = np.array(X)[idx].tolist()\n",
    "y = np.array(y)[idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward1(x):\n",
    "    h = torch.zeros(nhidden, 1, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "    for j in range(len(x)):  # for each char in a name\n",
    "        x_onehot = onehot(x[j])\n",
    "        h = W.mm(h) + U.mm(x_onehot)# + b\n",
    "        h = torch.tanh(h)\n",
    "    # h is output of RNN, a fancy CBOW embedding for variable-length sequence in x\n",
    "    # run through a final layer to map that h to a one-hot encoded predicted class\n",
    "    o = V.mm(h)# + Vb\n",
    "    o = o.reshape(1,nclasses)\n",
    "    o = softmax(o)\n",
    "    return o\n",
    "\n",
    "def forward(X:Sequence[Sequence]):#, apply_softmax=True):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "    outputs = []\n",
    "    for i in range(0, len(X)): # for each input record\n",
    "        o = forward1(X[i])\n",
    "        outputs.append( o[0] ) \n",
    "    return torch.stack(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just some matrices. First, set up hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ctoi = getvocab(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(c) -> torch.tensor:\n",
    "    v = torch.zeros((len(vocab),1), dtype=torch.float64)\n",
    "    v[ctoi[c]] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,688 training records, 29 features (chars), 18 target languages, state is 100-vector\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nhidden = 100\n",
    "\n",
    "n = len(X_train)\n",
    "nbatches = n // batch_size\n",
    "n = nbatches * batch_size\n",
    "X_train = X_train[0:n]\n",
    "y_train = y_train[0:n]\n",
    "\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(torch.unique(y_train))\n",
    "\n",
    "print(f\"{n:,d} training records, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using minibatch SGD, multiple records used to compute gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  1.6594 accur 0.516 | train loss  1.4484 accur 0.591 | valid loss  1.4815 accur 0.588\n",
      "Epoch:   2 accum loss  1.4116 accur 0.591 | train loss  1.3646 accur 0.601 | valid loss  1.3899 accur 0.599\n",
      "Epoch:   3 accum loss  1.2157 accur 0.645 | train loss  1.1060 accur 0.661 | valid loss  1.1590 accur 0.650\n",
      "Epoch:   4 accum loss  1.0757 accur 0.684 | train loss  1.0376 accur 0.693 | valid loss  1.1031 accur 0.677\n",
      "Epoch:   5 accum loss  1.0055 accur 0.706 | train loss  1.0093 accur 0.697 | valid loss  1.0961 accur 0.679\n",
      "Epoch:   6 accum loss  0.9502 accur 0.721 | train loss  0.9123 accur 0.723 | valid loss  1.0015 accur 0.706\n",
      "Epoch:   7 accum loss  0.9125 accur 0.732 | train loss  0.9010 accur 0.722 | valid loss  1.0109 accur 0.706\n",
      "Epoch:   8 accum loss  0.8713 accur 0.742 | train loss  0.8428 accur 0.740 | valid loss  0.9543 accur 0.707\n",
      "Epoch:   9 accum loss  0.8420 accur 0.749 | train loss  0.8403 accur 0.743 | valid loss  0.9732 accur 0.711\n",
      "Epoch:  10 accum loss  0.8250 accur 0.750 | train loss  0.8233 accur 0.744 | valid loss  0.9648 accur 0.724\n",
      "Epoch:  11 accum loss  0.8116 accur 0.757 | train loss  0.7783 accur 0.759 | valid loss  0.9217 accur 0.728\n",
      "Epoch:  12 accum loss  0.8034 accur 0.755 | train loss  0.7496 accur 0.768 | valid loss  0.9101 accur 0.732\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 25s, sys: 598 ms, total: 2min 26s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden,    nhidden,   dtype=torch.float64, requires_grad=True)\n",
    "U = torch.randn(nhidden,  nfeatures, dtype=torch.float64, requires_grad=True) # embed one-hot char vec\n",
    "V = torch.randn(nclasses, nhidden,   dtype=torch.float64, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.005, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        for i in range(p, p+batch_size): # do one batch\n",
    "            x = X_train[i]\n",
    "            h = torch.zeros(nhidden, 1, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "            for j in range(len(x)):  # for each char in a name\n",
    "                h = W.mm(h) + U.mm(onehot(x[j]))\n",
    "                h = torch.tanh(h)\n",
    "            # h is output of RNN, a fancy CBOW embedding for variable-length sequence in x\n",
    "            # run through a final layer to map that h to a one-hot encoded predicted class\n",
    "#             h = dropout(h, p=0.3)\n",
    "            o = V.mm(h)\n",
    "            o = o.reshape(1,nclasses)\n",
    "            o = softmax(o)\n",
    "            loss += cross_entropy(o, y_train[i])\n",
    "            correct = torch.argmax(o[0])==y_train[i]\n",
    "            epoch_training_accur += correct\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "#         print(loss.detach().item())\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    epoch_training_loss /= n\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train)\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_train\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid)\n",
    "        valid_loss = cross_entropy(o, y_valid)\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_valid\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing on 80% training from full data set:\n",
    "\n",
    "```\n",
    "CPU times: user 2min 25s, sys: 598 ms, total: 2min 26s\n",
    "Wall time: 2min 26s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
