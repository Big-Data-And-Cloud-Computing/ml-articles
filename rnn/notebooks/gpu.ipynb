{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on GPU with vectorized mini-batch SGD\n",
    "\n",
    "This notebook is part of article [Explaining RNNs without neural networks](https://explained.ai/rnn/index.html) and notebook [prep.ipynb](prep.ipynb) should be run this notebook as it needs files: `data/X.pkl` and `data/y.pkl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "from support import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "with open('data/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TESTING SUBSAMPLE\n",
    "idx = list(np.random.randint(0,len(X),size=2000))\n",
    "X = np.array(X)[idx].tolist()\n",
    "y = np.array(y)[idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_matrix(X, max_len, vocab, verbose=False):\n",
    "    X_onehot = torch.zeros((len(X),max_len,len(vocab)), dtype=torch.float64)\n",
    "    for i,x in enumerate(X):\n",
    "        pad = max_len - len(x)\n",
    "        for j,c in enumerate(x):\n",
    "            X_onehot[i, j+pad, ctoi[c]] = 1\n",
    "        if verbose: print(x); print(X_onehot[i].T, \"\\n\")\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X:Sequence[Sequence], max_len:int, vocab:dict):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "    X_onehot = onehot_matrix(X, max_len, vocab)\n",
    "    h = torch.zeros(nhidden, len(X), dtype=torch.float64, requires_grad=False)\n",
    "    for j in range(max_len):\n",
    "        x_step_t = X_onehot[:,j].T\n",
    "        h = W.mm(h) + U.mm(x_step_t)\n",
    "        h = torch.relu(h)        \n",
    "    o = V.mm(h)\n",
    "    o = o.T # make it batch_size x nclasses\n",
    "    o = softmax(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just some matrices. First, set up hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ctoi = getvocab(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(c) -> torch.tensor:\n",
    "    v = torch.zeros((len(vocab),1), dtype=torch.float64)\n",
    "    v[ctoi[c]] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,688 training records, batch size 32, 29 features (chars), 18 target languages, state is 100-vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "nhidden = 100\n",
    "batch_size = 32\n",
    "\n",
    "n = len(X_train)\n",
    "\n",
    "nbatches = n // batch_size\n",
    "n = nbatches * batch_size\n",
    "X_train = X_train[0:n]\n",
    "y_train = y_train[0:n]\n",
    "vocab, ctoi = getvocab(X)\n",
    "max_len = get_max_len(X)\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(torch.unique(torch.tensor(y_train)))\n",
    "\n",
    "print(f\"{n:,d} training records, batch size {batch_size}, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_onehot = onehot_matrix(X_train, max_len, vocab, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using pure SGD, one record used to compute gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  1.4481 accur 0.579 | train loss  1.0918 accur 0.673 | valid loss  1.1623 accur 0.647\n",
      "Epoch:   2 accum loss  1.0281 accur 0.694 | train loss  0.8645 accur 0.736 | valid loss  0.9437 accur 0.709\n",
      "Epoch:   3 accum loss  0.8719 accur 0.737 | train loss  0.7623 accur 0.770 | valid loss  0.8646 accur 0.735\n",
      "Epoch:   4 accum loss  0.7796 accur 0.765 | train loss  0.7012 accur 0.782 | valid loss  0.8284 accur 0.749\n",
      "Epoch:   5 accum loss  0.7409 accur 0.772 | train loss  0.7045 accur 0.786 | valid loss  0.8395 accur 0.747\n",
      "Epoch:   6 accum loss  0.7133 accur 0.783 | train loss  0.6779 accur 0.791 | valid loss  0.8089 accur 0.753\n",
      "Epoch:   7 accum loss  0.6949 accur 0.784 | train loss  0.6512 accur 0.798 | valid loss  0.8056 accur 0.759\n",
      "Epoch:   8 accum loss  0.6609 accur 0.793 | train loss  0.6281 accur 0.805 | valid loss  0.8231 accur 0.754\n",
      "Epoch:   9 accum loss  0.6939 accur 0.785 | train loss  0.6313 accur 0.804 | valid loss  0.8142 accur 0.761\n",
      "Epoch:  10 accum loss  0.6543 accur 0.797 | train loss  0.6479 accur 0.798 | valid loss  0.8488 accur 0.748\n",
      "Epoch:  11 accum loss  0.6569 accur 0.793 | train loss  0.5995 accur 0.814 | valid loss  0.8027 accur 0.757\n",
      "Epoch:  12 accum loss  0.6345 accur 0.801 | train loss  0.6163 accur 0.810 | valid loss  0.8284 accur 0.757\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 39s, sys: 15.8 s, total: 3min 55s\n",
      "Wall time: 43.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden, nhidden,   dtype=torch.float64, requires_grad=True)\n",
    "U = randn(nhidden,     nfeatures, dtype=torch.float64, requires_grad=True) # embed one-hot char vec\n",
    "V = randn(nclasses,    nhidden,   dtype=torch.float64, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.01, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total = 0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        batch_X = X_train[p:p+batch_size]\n",
    "        batch_y = y_train[p:p+batch_size]\n",
    "        batch_X_onehot = onehot_matrix(batch_X, max_len, vocab)\n",
    "        H = torch.zeros(nhidden, batch_size, dtype=torch.float64, requires_grad=False)\n",
    "        for t in range(max_len):\n",
    "            x_step_t = batch_X_onehot[:,t].T # make it len(vocab) x batch_size\n",
    "            H = W.mm(H) + U.mm(x_step_t)\n",
    "            H = torch.relu(H)\n",
    "        o = V.mm(h)\n",
    "        o = o.T # make it batch_size x nclasses\n",
    "        o = softmax(o)\n",
    "        loss = cross_entropy(o, batch_y)\n",
    "#         print(loss.item())\n",
    "        correct = torch.argmax(o, dim=1)==batch_y\n",
    "        epoch_training_accur += torch.sum(correct)\n",
    "        total += len(batch_y)\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    epoch_training_loss /= nbatches\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train, max_len, vocab)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==torch.tensor(y_train)\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid, max_len, vocab)\n",
    "        valid_loss = cross_entropy(o, y_valid).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==torch.tensor(y_valid)\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing on 80% training from full data set using a GeForce RTX 2080 Ti with 11G RAM.\n",
    "    \n",
    "```\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
