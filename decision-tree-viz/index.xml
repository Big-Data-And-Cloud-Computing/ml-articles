<chapter title="How to visualize decision tree models"
         author={[Terence Parr](http://parrt.cs.usfca.edu) and [Prince Grover](https://www.linkedin.com/in/groverpr)}>

Decision trees are the fundamental building block of [gradient boosting machines](http://explained.ai/gradient-boosting/index.html) and [Random Forests](https://en.wikipedia.org/wiki/Random_forest)\symbol{tm}, probably the two most popular machine learning models for structured data.  Visualizing decision trees is a tremendous aid when learning how these models work and later, in practice, when interpreting models.  Unfortunately, current visualization packages are rudimentary and not immediately helpful to the novice. For example, we couldn't find a library that visualizes how decision nodes split up feature space. Our library could be the first.  It also appears uncommon for libraries to support visualizing a specific feature vector as it weaves down through a tree's decision nodes; we could only find one image showing this (but we didn't exhaustively look through library APIs).

Terence has reached a point in his book on [machine learning book](https://mlbook.explained.ai/) (written with [Jeremy Howard](http://www.fast.ai/about/#jeremy)) where he needs to describe lots of decision trees. So, he and former [University of San Francisco MS in Data Science](https://www.usfca.edu/arts-sciences/graduate-programs/data-science) student Prince Grover teamed up to create a general package for [scikit-learn](https://github.com/scikit-learn/scikit-learn) decision tree visualization and model interpretation. This article demonstrates the results of this work, details the specific choices we made for visualization, and outlines the mashup of tools and techniques used in the implementation. The visualization software is part of a nascent Python machine learning library called [animl](https://github.com/parrt/animl).

We assume you're familiar with the basic mechanism of decision trees if you're interested in visualizing them, but let's start with a brief summary so that we're all using the same terminology.

<section title="Decision tree review">

A decision tree is a machine learning model based upon binary trees, trees with at most a left and right child.  A decision tree learns the relationship between feature vectors $\vec{x}$ and target values $y$ (in a training set) by examining and condensing training data into a binary tree of interior decision nodes and leaf prediction nodes.  (Notation: vectors are in bold and scalars are in italics.)

Each leaf in the decision tree is responsible for making a specific prediction. For regression trees, the prediction is a value in the target space, such as price.  For classifier trees, the prediction is a target category/class (represented as an integer in scikit), such as cancer or not-cancer. A decision tree carves up the feature space into groups of feature vectors that share similar target values and each leaf represents one of these groups.  For regression, "similar" means a low variance between target values and, for classification, "similar" means that most or all targets are of a single class.

Any path from the root of the decision tree to a specific $y$ leaf predictor passes through a series of (internal) decision nodes. Each decision node compares a single feature's value in $\vec{x}$, $x_i$, with a specific \first{split point} value learned during training. For example, in a model predicting apartment rent prices, decision nodes would test features such as the number of bedrooms and number of bathrooms.  Even in a classifier with discrete target values, decision nodes still compare numeric *feature* values because scitkit's decision tree implementation assumes that all features are numeric. Categorical variables must be [one hot encoded](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/), [binned](https://www.analyticsvidhya.com/blog/2015/11/easy-methods-deal-categorical-variables-predictive-modeling/), [label encoded](http://forums.fast.ai/t/to-label-encode-or-one-hot-encode/6057), etc...

To train a decision node, the model examines a subset of the training observations (or the full training set at the root). The node's feature and split point within that feature space are chosen during training to split the observations into left and right buckets (subsets). The left bucket has observations whose $x_i$ feature values are all less than the split point and the right bucket has observations whose $x_i$ is greater than the split point.  The goal is to pick a feature and split point in that feature space so that, within the left and right buckets, the observations have similar target values. (This selection process is generally done through exhaustive comparison of features and  feature values.) Tree construction proceeds recursively by creating decision nodes for the left bucket and the right bucket.  Given a bucket with suitably similar target values, the model creates a leaf node rather than a decision node. The leaf predicts the mean (regression) or most common target (classification).

<section title="The key elements of decision tree visualization">
	
Decision tree visualizations would optimally highlight the following important elements:

<ul>
	<li>Decision node feature versus target value distributions, which we call feature-target space in this article. We want to know how separable the target values are based upon the feature and a split point.
	<li>Decision node feature name and feature split value.  We need to know which feature each decision node is testing and where in that space the nodes splits the observations.
	<li>Leaf node purity, which affects our prediction confidence. Leaves with low variance among the target values (regression) or an overwhelming majority target class (classification) are much more reliable predictors.
	<li>Leaf node prediction value.  What is this leaf actually predicting from the collection of target values?
	<li>Numbers of samples in decision nodes.  Sometimes it's useful to know where all most of the samples are being routed through the decision nodes.
	<li>Numbers of samples in leaf nodes.  Our goal is a decision tree with fewer, larger and purer leaves. Nodes with too few samples are possible indications of overfitting.
	<li>How a specific feature vector is run down the tree to a leaf. This helps explain why a particular feature vector gets the prediction it does. For example, in a regression tree predicting apartment rent prices, we might find a feature vector routed into a high predicted price leaf because of a decision node that checks for more than three bedrooms.
</ul>

<section title="Gallery of decision tree visualizations">
	
Before digging into the previous state-of-the-art visualizations, we'd like to give a little spoiler to show what's possible. This section highlights some samples visualizations we built from scikit regression and classification decision trees on a few data sets. You can also check out the	
[full gallery](https://github.com/parrt/animl/tree/master/testing/samples) 
and [code to generate all samples](https://github.com/parrt/animl/blob/master/testing/gen_samples.py).

<table>
	<tr>
		<th width="50%"><th width="50%">
	<tr>
		<td>[WINE](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine) 3-class top-down orientation
		<td>[BREAST CANCER](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer) 2-class left-to-right
	<tr>
		<td>[<img src="images/samples/wine-TD-2.svg" width="100%">](images/samples/wine-TD-2.svg)
		<td>[<img src="images/samples/breast_cancer-LR-3.svg" width="100%">](images/samples/breast_cancer-LR-3.svg)
	<tr>
		<td>[IRIS](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris) 3-class with sample $\vec{x}$
		<td>[USER KNOWLEDGE RATING](https://archive.ics.uci.edu/ml/datasets/User+Knowledge+Modeling) 4-class
	<tr>
		<td>[<img src="images/samples/iris-TD-3-X.svg" width="100%">](images/samples/iris-TD-3-X.svg)
		<td>[<img src="images/samples/knowledge-LR-3.svg" width="100%">](images/samples/knowledge-LR-3.svg)
	<tr>
		<td>[DIGITS](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits) 10-class 
		<td>[DIABETES](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html) with sample $\vec{x}$
	<tr>
		<td>[<img src="images/samples/digits-LR-3.svg" width="100%">](images/samples/digits-LR-3.svg)
		<td>[<img src="images/samples/diabetes-TD-3-X.svg" width="100%">](images/samples/diabetes-TD-3-X.svg)	
	<tr>
		<td>[BOSTON](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) with sample $\vec{x}$
		<td>[SWEETS](http://mldata.org/repository/data/viewslug/ratings-of-sweets-sweetrs/) with sample $\vec{x}$
	<tr>
		<td>[<img src="images/samples/boston-TD-3-X.svg" width="100%">](images/samples/boston-TD-3-X.svg)
		<td>[<img src="images/samples/sweets-TD-3-X.svg" width="100%">](images/samples/sweets-TD-3-X.svg)
	<tr>
		<td>USER KNOWLEDGE RATING 4-class non-fancy
		<td>DIABETES non-fancy
	<tr>
		<td>[<img src="images/samples/knowledge-TD-4-simple.svg" width="100%">](images/samples/knowledge-TD-4-simple.svg)
		<td>[<img src="images/samples/boston-LR-5-X-simple.svg" width="100%">](images/samples/boston-LR-5-X-simple.svg)

</table>	

<section title="A comparison to previous state-of-the-art visualizations">
	
If you do a web search for "visualizing decision trees" you will quickly find a **Python** solution provided by the awesome scikit folks: [sklearn.tree.export_graphviz](http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html).  With more work, you can find visualizations for **R** and even **SAS** and **IBM**. In this section, we collect the various decision tree visualizations we could find and compare them to the visualizations made by our `animl` library. We give a more detailed discussion of our visualizations in the next section.


Let's start with the [default scitkit visualization](http://scikit-learn.org/stable/modules/tree.html) of a decision tree on the well-known [IRIS](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris) data set (click on images to enlarge).

<table>
	<tr>
		<th width="50%">
		<th width="50%">
			<tr>
				<td>Default scikit IRIS visualization
				<td>Our `animl` IRIS visualization
	<tr>
		<td>[<img src="images/iris-scikit.png" width="100%">](images/iris-scikit.png)
		<td>[<img src="images/samples/iris-TD-5.svg" width="100%">](images/samples/iris-TD-5.svg)
</table>
		
The scikit tree does a good job of representing the tree structure, but we have a few quibbles.  The colors aren't the best and it's not immediately obvious why some of the nodes are colored and some aren't.  If the colors represent predicted class for this classifier, one would think just the leaves would be colored because only leaves have predictions. (It turns out the non-colored nodes have no majority prediction.) Including the gini coefficient (certainty score) costs space and doesn't really help the beginners to interpret trees. The count of samples of the  various target classes in each node is somewhat useful, though, a histogram would be even better. A target class color legend would be nice.  Finally, using true and false as the edge labels isn't as clear as, say, labels $<$ and $\ge$. The most obvious difference is that our decision nodes show feature distributions as overlapping stacked-histograms, one histogram per target class. Also, our leaf size is proportional to the number of samples in that leaf.

Scikit uses the same visualization approach for decision tree regressors. For example, here is scikit's visualization using the [BOSTON](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) data set, with `animl`'s version for comparison (click to enlarge images):

<table>
	<tr>
		<th width="50%">
		<th width="50%">
			<tr>
				<td>Default scikit BOSTON visualization
				<td>Our `animl` BOSTON visualization
	<tr>
		<td>[<img src="images/boston-scikit.png" width="100%">](images/boston-scikit.png)
		<td>[<img src="images/samples/boston-TD-3.svg" width="100%">](images/samples/boston-TD-3.svg)
</table>

In the scikit tree, it's not immediately clear what the use of color implies, but after studying the image, darker images indicate higher predicted target values. As before, our decision nodes show the feature space distribution, this time using a feature versus target value scatterplot.  The leaves use strip plots to show the target value distribution; leaves with more dots naturally have a higher number of samples.

**R** programmers also have access to a package for [visualizing decision trees](http://blog.revolutionanalytics.com/2013/06/plotting-classification-and-regression-trees-with-plotrpart.html), which gives similar results to scikit but with nice edge labels:

[<img src="images/R-tree.png" width="40%">](images/R-tree.png)

If you dig really hard, you will find that **SAS** and **IBM** provide (non-Python-based) decision tree visualizations.  Starting with SAS, we see that their decision nodes include a bar chart related to the node's sample target values and other details:
	
<table>
	<tr>
		<th width="50%">
		<th width="50%">
			<tr>
				<td>SAS visualization
				<td>SAS visualization (best image quality we could find with numeric features)
	<tr>
		<td>[<img src="images/sas-tree.png" width="100%">](images/sas-tree.png)
		<td>[<img src="images/sas-tree2.jpeg" width="100%">](images/sas-tree2.jpeg)
</table>


Indicating the size of the left and right buckets via edge width is a nice touch. But, those bar charts are hard to interpret because they have no horizontal axis.  Decision nodes testing categorical variables (left image) have exactly one bar per category so they must represent simple category counts, rather than feature distributions. For numeric features (right image), SAS decision nodes show a histogram of either target  or feature space (we can't tell from the image). SAS node bar charts / histograms appear to illustrate just target values, which tells us nothing about how the feature space was split.

The SAS tree on the right appears to highlight a path through the decision tree for a specific unknown feature vector, but we couldn't find any other examples from other tools and libraries.  The ability to visualize a specific vector run down the tree does not seem to be generally available.

Moving on to IBM software, here is a nice visualization, that also shows decision node category counts as bar charts, from [IBM's Watson analytics](https://www.ibm.com/support/knowledgecenter/en/SS4QC9/com.ibm.solutions.wa_an_overview.2.0.0.doc/wa_discover_viz_expl_insigths_dec_tree.html) (on the [TITANIC](https://www.kaggle.com/c/titanic/data) data set):

[<img src="images/ibm-tree.png" width="60%">](images/ibm-tree.png)

IBM's earlier **SPSS** product also had decision tree visualizations:

<table>
	<tr>
		<th width="50%">
		<th width="50%">
			<tr>
				<td>SPSS visualization
				<td>SPSS visualization
	<tr>
		<td>[<img src="images/spss-tree.png" width="100%">](images/spss-tree.png)
		<td>[<img src="images/spss-tree2.png" width="100%">](images/spss-tree2.png)
</table>

These SPSS decision nodes seem to give the same SAS-like bar chart of sample target class counts.

All of the visualizations we encountered from the major players were useful, but we were most inspired by the eye-popping visualizations in [A visual introduction to machine learning](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/), which shows an (animated) decision tree like this:

[<img src="images/vizml-tree.png" width="75%">](images/vizml-tree.png)

This visualization has three unique characteristics over previous work, aside from the animation:

<ul>
	<li>the decision nodes show how the feature space is split
	<li>the split points for decision nodes are shown visually (as a wedge) in the distribution
	<li>the leaf size is proportional to the number of samples in that leaf
</ul>

While that visualization is a hardcoded animation for educational purposes, it points in the right direction.

<section title="Our decision tree visualizations">
	
Other than the educational animation in [A visual introduction to machine learning](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/), we couldn't find a decision tree visualization package that illustrates how the feature space is split up at  decision nodes (feature-target space).  This is the critical operation performed during decision tree model training and is what newcomers should focus on, so we'll start by examining decision node visualizations for both classification and regression trees. 

<subsection title="Visualizing feature-target space">

Training of a decision node chooses feature $x_i$ and split value within $x_i$'s range of values (feature space) to group samples with similar target values into two buckets.  Just to be clear, training involves examining the relationship between features and target values. Unless decision nodes show feature-target space in some way, the viewer cannot see how and why training arrived at the split value. To highlight how decision nodes carve up the feature space, we trained a regressor and classifier with a single (AGE) feature ([code to generate images](https://github.com/parrt/animl/blob/master/testing/paper_examples.py)).  Here's a regressor decision tree trained on BOSTON data, with node ID labeling turned on for discussion purposes here:

[<img src="images/boston-TD-AGE.svg" width="100%">](images/boston-TD-AGE.svg)

Horizontal dashed lines indicate the target mean for the left and right buckets in decision nodes; a vertical dashed line indicates the split point in feature space. The black wedge highlights the split point and identifies the exact split value. Leaf nodes indicate the target prediction (mean) with a dashed line.

All decision nodes are restricted to the single AGE feature to demonstrate that our visualization forces the same horizontal axis range for all nodes testing the same feature, leaving blank regions rather than zooming in. As we descend through decision nodes, the sample AGE values are boxed into narrower and narrower regions.  Combining the AGE feature-target space (regions) from two siblings yields the parent's feature-target space. For example, combining the AGE regions in nodes 1 and 8, yields the node 0 feature-target space and combining the AGE regions from nodes 9 and 12 yields the node 8 feature-target space. The prediction leaves are not very pure and using a single variable leads to a poor model, but this restricted example demonstrates how decision trees carve up feature space.

While a decision tree implementation is virtually identical for both classifier and regressor decision trees, the way we interpret them is very different so our visualizations are distinct for the two cases.  For a regressor, showing feature-target space is best done with a scatterplot of feature versus target.  For classifier, however, the target is a category rather than a number and so we chose to illustrate feature-target space using histograms as an indicator of feature space distributions.  Here's a classifier tree trained on the USER KNOWLEDGE data, again with a single feature (PEG) and with nodes labeled for discussion purposes:

[<img src="images/knowledge-TD-PEG.svg" width="100%">](images/knowledge-TD-PEG.svg)

Ignoring color, the histogram shows the PEG feature space distribution.  Adding color, gives us an indication of the relationship between feature space and target class. For example, in node 0, we can see that samples with `very_low` target class are clustered at the low end of PEG feature space and samples with `High` target class are clustered at the high-end. As with the regressor, the feature space of a left child is everything to the left of the parent's split point in the same  feature space; similarly for the right child.  For example, combining the histograms of nodes 9 and 12 yields the histogram of node 8. We force the horizontal axis range to be the same for all PEG decision nodes so that decision nodes lower in the tree clearly box in narrower regions that are more and more pure.

We use a stacked histogram so that overlap is clear in the feature space between samples with different target classes.  Note that the height in the Y axis of the stacked histogram is the total number of samples from all classes; multiple class counts are stacked on top of each other. 

When there are more than four or five classes, the stacked histograms are difficult to read and so we recommend setting the histogram type parameter to `bar` not `barstacked` in this case.  With high cardinality target categories, the overlapping distributions are harder to visualize and things break down, so we set a limit of 10 target classes. Here's a shallow tree example using the 10-class DIGITS data set using non-stacked histograms:

[<img src="images/samples/digits-TD-2.svg" width="65%">](images/samples/digits-TD-2.svg)

<subsection title="It's all about the details">

Thus far we've skipped over many of the visual cues and details that we  obsessed over during construction of the library and so we hit the key elements here.

Our classifier tree visualizations use node size to give visual cues about the number of samples associated with each node.  Histograms get proportionally shorter as the number of samples in the node decrease and leaf node diameters get smaller.  The feature space (horizontal axis) is always the same width and the same range for a given feature, which makes it much easier to compare the feature-target spaces of different nodes. The bars of all histograms are the same width in pixels. We use just the start/stop range labels for both horizontal and vertical axes to reduce clutter. 

<img src="images/knowledge-dec-node.png" width="35%"><img src="images/knowledge-dec-node2.png" width="35%">

We use a pie chart for classifier leaves, despite their bad reputation.  For the purpose of indicating purity, the viewer only needs an indication of whether there is a single strong majority category. The viewer does not need to see the exact relationship between elements of the pie chart, which is one key area where pie charts fail. The color of the pie chart majority slice gives the leaf prediction. 

<img src="images/knowledge-leaf.png" width="8%">

Turning to regressor trees now, we make sure that the target (vertical) axis of all decision nodes is the same height and the same range to make comparing nodes easier. Regressor feature space (horizontal axis) is always the same width and the same range for a given feature.  We set a low alpha for all scatterplot dots so that increased target value density corresponds to darker color.  

<img src="images/boston-dec-node.png" width="30%">

Regressor leaves also show the same range vertically for the target space, but leaves are a bit taller than decision nodes so it's easier to identify nodes with high or low predictions. We use a strip plot rather than, say, a box plot because the strip plot shows the distribution explicitly while implicitly showing the number of samples by the number of dots. (We also write out the number of samples in text for leaves.) The leaf prediction is the distribution center of mass (mean) of the strip plot, which we highlight with a dashed line.

<img src="images/boston-leaf.png" width="25%">

There are also a number of miscellaneous details that we think improve the quality of the diagrams:

<ul>
	<li>Classifiers include a legend
	<li>All colors were handpicked from colorblind safe palletes, one handpicked pallete per number of target categories (2 through 10)
	<li>We use a gray rather than black for text because it's easier on the eyes
	<li>Lines are hairlines
	<li>We draw outlines of bars in bar charts and slices in pie charts
</ul>

<subsection title="Visualizing tree interpretation of a single observation">

To figure out how model training arrives at a specific tree, all of the action is in the feature-space splits of the decision nodes, which we just discussed. Now, let's take a look at visualizing how a specific feature vector yields a specific prediction. The key here is to examine the decisions taken along the path from the root to the leaf predictor node. 

Decision-making within a node is straightforward: take the left path if feature $x_i$ in test vector $\vec{x}$ is less than the split point, otherwise take the right path. To highlight the decision-making process, we have to highlight the comparison operation. For decision nodes along the path to the leaf predictor node, we show an orange wedge at position $x_i$ in the horizontal feature space. This makes the comparison easy to see; if the orange wedge is to the left of the black wedge, go left else go right. Decision nodes involved in the prediction process are surrounded by boxes with dashed lines and the child edges are thicker and colored orange. Here are two sample trees showing test vectors (click on images to expand):

<table>
	<tr>
		<th width="50%">
		<th width="50%">
			<tr>
				<td>KNOWLEDGE data with test vector
				<td>DIABETES data with test vector
	<tr>
		<td>[<img src="images/samples/knowledge-TD-3-X.svg" width="100%">](images/samples/knowledge-TD-3-X.svg)
		<td>[<img src="images/samples/diabetes-TD-3-X.svg" width="100%">](images/samples/diabetes-TD-3-X.svg)
</table>

The test vector $\vec{x}$ with feature names and values appears below the leaf predictor node (or to the right in left-to-right orientation). The test vector highlights the features used in one or more decision nodes.  When the number of features reaches a threshold of 20 (10 for left-to-right orientation),  test vectors do not show unused features to avoid unwieldly test vectors.


<subsection title="Left-to-right orientation">

Some users have a preference for left-to-right orientation instead of top-down and sometimes the nature of the tree simply flows better left-to-right. Sample feature vectors can still be run down the tree with the left-to-right orientation. Here are some examples (click on the images to enlarge):
	
<table>
	<tr>
		<th width="45%"><th width="45%">
	<tr>
		<td>WINE
		<td>DIABETES
	<tr>
		<td>[<img src="images/samples/wine-LR-3.svg" width="100%">](images/samples/wine-LR-3.svg)
		<td>[<img src="images/samples/diabetes-LR-3.svg" width="100%">](images/samples/diabetes-LR-3.svg)
	<tr>
		<td>WINE with sample $\vec{x}$
		<td>DIABETES with sample $\vec{x}$
	<tr>
		<td>[<img src="images/samples/wine-LR-2-X.svg" width="100%">](images/samples/wine-LR-2-X.svg)
		<td>[<img src="images/samples/diabetes-LR-2-X.svg" width="100%">](images/samples/diabetes-LR-2-X.svg) 
</table>
	
<subsection title="Simplified non-fancy layout">

To evaluate the generality of a decision tree, if it often helps to get a high-level overview of the tree.  This generally means examining things like tree shape and size, but more importantly, it means looking at the leaves.  We'd like to know how many samples each leaf has, how pure the target values are, and just generally where most of the weight of samples falls.  


Getting an overview of the large tree

	
get an overview of the tree and where all of the weight falls, which nodes appear and less on the decision nodes.  you can see very large trees but you have to do some scrolling and zooming.
	
	[<img src="images/samples/knowledge-TD-15-X-simple.svg" width="55%">](images/samples/knowledge-TD-15-X-simple.svg)

For regressors, it looks better left to right, otherwise it is too wide.
	
	[<img src="images/samples/boston-TD-5-X-simple.svg" width="100%">](images/samples/boston-TD-5-X-simple.svg)

<section title="Code sample">
		
```
regr = tree.DecisionTreeRegressor(max_depth=max_depth)
boston = load_boston()
regr = regr.fit(boston.data, boston.target)
```

```
st = dtreeviz(regr, boston.data, boston.target, target_name='price',
              feature_names=boston.feature_names)
```

```
g = graphviz.Source(st, format='pdf')
g.render(directory=".", filename="boston.pdf", view=False, cleanup=True)
```

```
g = graphviz.Source(st, format='pdf')
g.view()
```

```
X = boston.data[np.random.randint(0, len(boston.data)),:]

st = dtreeviz(regr, boston.data, boston.target, target_name='price',
              feature_names=boston.feature_names,
              X=X)
```

for classifier we need the class names too.

<section title="Our implementation">
	
	shadow tree
	
	graphviz/dot

	matplotlib

	load svg was issue

	then must parse svg to get size

	future: bottom-justify histograms in classifier trees. some wedge labels overlap with axis. thicken incoming edges for nodes with lots of samples.
	
<section title="What we tried and rejected">

classifier decision nodes

	<img src="images/kde.png" width="50%">

	<img src="images/kde-leaf.png" width="15%">
	
	<img src="images/bubble.png" width="70%">

regression leaf nodes		

	<img src="images/dual-leaf.png" width="15%">
		
	<img src="images/non-strip-plot.png" width="30%">
		
<section title="Lessons learned">

We are definitely not visualization aficionados, but for this specific problem we banged on it until we got effective diagrams.

	there are lots of visual effects one can choose from to visualize data: color, line thickness, line style, different kinds of plots, size (area, length, graph height, ...), alpha, text styles (color, font, bold, italics, size), graph annotations, visual flow.  Everything has to be for a reason don't just use color because colors are nice. they have to mean something.  In Tufte's seminar I learned that you can pack a lot of information into a rich diagram; humans can deal with it, but it can't be a mishmash.
	
	as our subtlety list shows, there's more to it.  same axis, same scale etc.